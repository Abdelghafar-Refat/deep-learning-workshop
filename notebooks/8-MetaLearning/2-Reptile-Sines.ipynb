{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, autograd as ag\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "plot = True\n",
    "\n",
    "## Inner Optimisations\n",
    "innerstepsize = 0.02 # stepsize in inner SGD\n",
    "innerepochs = 1 # number of epochs of each inner SGD\n",
    "\n",
    "## Outer Optimisations\n",
    "# stepsize of outer optimization, i.e., meta-optimization\n",
    "outerstepsize0 = 0.1 \n",
    "# number of outer updates; each iteration we sample one task and update on it\n",
    "niterations = 30000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task distribution\n",
    "x_all = np.linspace(-5, 5, 50)[:,None] # All of the x points\n",
    "ntrain = 10 # Size of training minibatches\n",
    "def gen_task():\n",
    "    \"Generate classification problem\"\n",
    "    phase = rng.uniform(low=0, high=2*np.pi)\n",
    "    ampl = rng.uniform(0.1, 5)\n",
    "    f_randomsine = lambda x : np.sin(x + phase) * ampl\n",
    "    return f_randomsine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model. Reptile paper uses ReLU, but Tanh gives slightly better results\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(64, 1),\n",
    ")\n",
    "\n",
    "def totorch(x):\n",
    "    return ag.Variable(torch.Tensor(x))\n",
    "\n",
    "def train_on_batch(x, y):\n",
    "    x = totorch(x)\n",
    "    y = totorch(y)\n",
    "    model.zero_grad()\n",
    "    ypred = model(x)\n",
    "    loss = (ypred - y).pow(2).mean()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.data -= innerstepsize * param.grad.data\n",
    "\n",
    "def predict(x):\n",
    "    x = totorch(x)\n",
    "    return model(x).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a fixed task and minibatch for visualization\n",
    "f_plot = gen_task()\n",
    "xtrain_plot = x_all[rng.choice(len(x_all), size=ntrain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reptile training loop\n",
    "for iteration in range(niterations):\n",
    "    weights_before = deepcopy(model.state_dict())\n",
    "    \n",
    "    # Generate task\n",
    "    f = gen_task()\n",
    "    y_all = f(x_all)\n",
    "    \n",
    "    # Do SGD on this task\n",
    "    inds = rng.permutation(len(x_all))\n",
    "    for _ in range(innerepochs):\n",
    "        for start in range(0, len(x_all), ntrain):\n",
    "            mbinds = inds[start:start+ntrain]\n",
    "            train_on_batch(x_all[mbinds], y_all[mbinds])\n",
    "            \n",
    "    # Interpolate between current weights and trained weights from this task\n",
    "    # I.e. (weights_before - weights_after) is the meta-gradient\n",
    "    weights_after = model.state_dict()\n",
    "    outerstepsize = outerstepsize0 * (1 - iteration / niterations) # linear schedule\n",
    "    model.load_state_dict({name : \n",
    "        weights_before[name] + (weights_after[name] - weights_before[name]) * outerstepsize \n",
    "        for name in weights_before})\n",
    "\n",
    "    # Periodically plot the results on a particular task and minibatch\n",
    "    if plot and iteration==0 or (iteration+1) % 1000 == 0:\n",
    "        plt.cla()\n",
    "        f = f_plot\n",
    "        weights_before = deepcopy(model.state_dict()) # save snapshot before evaluation\n",
    "        plt.plot(x_all, predict(x_all), label=\"pred after 0\", color=(0,0,1))\n",
    "\n",
    "        for inneriter in range(32):\n",
    "            train_on_batch(xtrain_plot, f(xtrain_plot))\n",
    "            if (inneriter+1) % 8 == 0:\n",
    "                frac = (inneriter+1) / 32\n",
    "                plt.plot(x_all, predict(x_all), \n",
    "                         label=\"pred after %i\"%(inneriter+1), color=(frac, 0, 1-frac))\n",
    "                \n",
    "        plt.plot(x_all, f(x_all), label=\"true\", color=(0,1,0))\n",
    "        lossval = np.square(predict(x_all) - f(x_all)).mean()\n",
    "        plt.plot(xtrain_plot, f(xtrain_plot), \"x\", label=\"train\", color=\"k\")\n",
    "        plt.ylim(-4,4)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        #plt.pause(0.01)\n",
    "        model.load_state_dict(weights_before) # restore from snapshot\n",
    "        \n",
    "        print(f\"-----------------------------\")\n",
    "        print(f\"iteration               {iteration+1}\")\n",
    "        # would be better to average loss over a set of examples, \n",
    "        #   but this is optimized for brevity\n",
    "        print(f\"loss on plotted curve   {lossval:.3f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
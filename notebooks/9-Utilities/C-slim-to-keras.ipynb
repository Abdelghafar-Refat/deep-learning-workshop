{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Copy a Pretrained Network between Frameworks\n",
    "\n",
    "Since a large CNN is very time-consuming to train (even on a GPU), and requires huge amounts of data, is there any way to use a pre-calculated one instead of retraining the whole thing from scratch?  \n",
    "\n",
    "This notebook shows how this can be done, so that the same data can be used in a different framework.\n",
    "\n",
    "The code here is slightly rough-and-ready, since to be interested in doing it assumes some level of familiarity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Add TensorFlow Slim Model Zoo to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "better_instructions = '2-CNN/4-ImageNet/4-ImageClassifier-inception_tf.ipynb'\n",
    "\n",
    "if not os.path.isfile( '../models/tensorflow_zoo/models/README.md' ):\n",
    "    print(\"Please follow the instructions in %s to get the Slim-Model-Zoo installed\" % better_instructions)\n",
    "else:\n",
    "    sys.path.append(slim_models_dir + \"/models/slim\")\n",
    "    print(\"Model Zoo model code installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import dataset_utils\n",
    "\n",
    "checkpoint_file = '../data/tensorflow_zoo/checkpoints/inception_v1.ckpt'\n",
    "if not os.path.isfile( checkpoint_file ):\n",
    "    print(\"Please follow the instructions in %s to get the Checkpoint installed\" % better_instructions)\n",
    "else:\n",
    "    print(\"Checkpoint available locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('../data/imagenet_synset_words.txt'):\n",
    "    print(\"Please follow the instructions in %s to get the synset_words file\" % better_instructions)\n",
    "else:    \n",
    "    print(\"ImageNet synset labels available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "from nets import inception\n",
    "#from preprocessing import inception_preprocessing\n",
    "\n",
    "#image_size = inception.inception_v1.default_image_size\n",
    "#image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if False:\n",
    "    # Define the pre-processing chain within the graph - from a raw image\n",
    "    input_image = tf.placeholder(tf.uint8, shape=[None, None, None, 3], name='input_image')\n",
    "    processed_image = inception_preprocessing.preprocess_image(input_image, image_size, image_size, is_training=False)\n",
    "    processed_images = tf.expand_dims(processed_image, 0)\n",
    "\n",
    "processed_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_image')\n",
    "\n",
    "# Create the model - which uses the above pre-processing on image\n",
    "#   it also uses the default arg scope to configure the batch norm parameters.\n",
    "print(\"Model builder starting\")\n",
    "\n",
    "# Here is the actual model zoo model being instantiated :\n",
    "with slim.arg_scope(inception.inception_v1_arg_scope()):\n",
    "    logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False)\n",
    "#probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "# Create an operation that loads the pre-trained model from the checkpoint\n",
    "init_fn = slim.assign_from_checkpoint_fn(checkpoint_file, slim.get_model_variables('InceptionV1') )\n",
    "\n",
    "print(\"Model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get the values from the TF model into a NumPy structure\n",
    "Mostly because it's easier for me to reason about NumPy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "capture_names =[] \n",
    "capture_values=dict()\n",
    "\n",
    "# Now let's run the pre-trained model\n",
    "with tf.Session() as sess:\n",
    "    # This is the loader 'op' we defined above\n",
    "    init_fn(sess)  \n",
    "    \n",
    "    # This is two ops : one merely loads the image from numpy, \n",
    "    #   the other runs the network to get the class probabilities\n",
    "    #np_image, np_probs = sess.run([numpyish_image, probabilities], feed_dict={input_image:im_sq})\n",
    "    \n",
    "    variables = tf.trainable_variables()\n",
    "    #variables = tf.model_variables()  # includes moving average information\n",
    "    for variable in variables:\n",
    "        name, value = variable.name, variable.eval()\n",
    "        capture_names.append(name)\n",
    "        capture_values[name] = value\n",
    "        print(\"%20s %s \" % (value.shape, name, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----------\n",
    "## GOT TO HERE\n",
    "\n",
    "Now go through the input images and feature-ize them at the 'logit level' according to the pretrained network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "classes = sorted( [ d for d in os.listdir(CLASS_DIR) if os.path.isdir(\"%s/%s\" % (CLASS_DIR, d)) ] )\n",
    "classes # Sorted for for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = dict(filepath=[], features=[], target=[])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # This is the loader 'op' we defined above\n",
    "    init_fn(sess)  \n",
    "    print(\"Loaded pre-trained model\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    for class_i, directory in enumerate(classes):\n",
    "        for filename in os.listdir(\"%s/%s\" % (CLASS_DIR, directory, )):\n",
    "            filepath = '%s/%s/%s' % (CLASS_DIR, directory, filename, )\n",
    "            if os.path.isdir(filepath): continue\n",
    "                \n",
    "            im = plt.imread(filepath)\n",
    "            im_sq = crop_middle_square_area(im)\n",
    "\n",
    "            # This is two ops : one merely loads the image from numpy, \n",
    "            #   the other runs the network to get the 'logit features'\n",
    "            rawim, np_logits = sess.run([numpyish_image, logits], feed_dict={input_image:im_sq})\n",
    "    \n",
    "            train['filepath'].append(filepath)\n",
    "            train['features'].append(np_logits[0])\n",
    "            train['target'].append( class_i )\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(rawim.astype('uint8'))\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.text(320, 50, '{}'.format(filename), fontsize=14)\n",
    "            plt.text(320, 80, 'Train as class \"{}\"'.format(directory), fontsize=12)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(train),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Use the SVM model to classify the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_image_files = [f for f in os.listdir(CLASS_DIR) if not os.path.isdir(\"%s/%s\" % (CLASS_DIR, f))]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # This is the loader 'op' we defined above\n",
    "    init_fn(sess)  \n",
    "    print(\"Loaded pre-trained model\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for filename in sorted(test_image_files):\n",
    "        im = plt.imread('%s/%s' % (CLASS_DIR,filename,))\n",
    "        im_sq = crop_middle_square_area(im)\n",
    "\n",
    "        # This is two ops : one merely loads the image from numpy, \n",
    "        #   the other runs the network to get the class probabilities\n",
    "        rawim, np_logits = sess.run([numpyish_image, logits], feed_dict={input_image:im_sq})\n",
    "\n",
    "        prediction_i = classifier.predict([ np_logits[0] ])\n",
    "        decision     = classifier.decision_function([ np_logits[0] ])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(rawim.astype('uint8'))\n",
    "        plt.axis('off')\n",
    "\n",
    "        prediction = classes[ prediction_i[0] ]\n",
    "\n",
    "        plt.text(350, 50, '{} : Distance from boundary = {:5.2f}'.format(prediction, decision[0]), fontsize=20)\n",
    "        plt.text(350, 75, '{}'.format(filename), fontsize=14)\n",
    "    \n",
    "print(\"DONE : %6.2f seconds each\" %(float(time.time() - t0)/len(test_image_files),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = 'test.1_all.hdf5_fac1.0.npz'\n",
    "#test_file = 'test.1_all.hdf5_base.npz'\n",
    "#test_file = 'dev.1_all.hdf5_base.npz'\n",
    "test_path = './orig/omerlevy-bidaf_no_answer-2e9868b224e4/relation_splits/'\n",
    "\n",
    "data = np.load( os.path.join(test_path,test_file) )\n",
    "data.files  # ['predictions', 'targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = data['predictions'], data['targets']\n",
    "preds.shape, targs.shape  # ((10, 1, 5, 128), (10, 1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess(pred, targ):\n",
    "    #print(pred.shape, targ.shape)  # (5, 128) (128,)\n",
    "    \n",
    "    #for i,v in enumerate(list(targ)):\n",
    "    #    if v==0: continue\n",
    "    #    print(i, v)  # 1->2 is subject, 3->4 is required answer(s)\n",
    "        \n",
    "    #  Get the starts and ends from targ\n",
    "    targ_q_starts = [i for i,v in enumerate(list(targ)) if v==1]\n",
    "    targ_a_starts = [i for i,v in enumerate(list(targ)) if v==3]\n",
    "    #print(targ_ans_starts)\n",
    "    \n",
    "    targ_q_arr, targ_a_arr = [],[]\n",
    "    for i in targ_q_starts:                    # find next '2'\n",
    "        # problem at idx=1218 ??\n",
    "        if 2 in list(targ[i:]):\n",
    "            targ_q_arr.append( (i, i+list(targ[i:]).index(2) ) )\n",
    "    for i in targ_a_starts:                    # find next '4'\n",
    "        # problem at idx=4480 ??\n",
    "        if 4 in list(targ[i:]):\n",
    "            targ_a_arr.append( (i, i+list(targ[i:]).index(4) ) )\n",
    "    print( 'targets : q=', targ_q_arr, ', a=', targ_a_arr )\n",
    "    \n",
    "    if False:\n",
    "        for i,v in enumerate(list(pred.T)):\n",
    "            print(i, [\"%+7.4f\" % f for f in list(v)])\n",
    "            \n",
    "    # This is pretty 'audacious', since it wasn't trained to succeed at doing this\n",
    "    print(\"                      answer: \", np.argmax(pred[3,:]), np.argmax(pred[4,:]),  )\n",
    "    \n",
    "    if False:\n",
    "        for i,v in enumerate(list(pred.T)):\n",
    "            c = np.argmax(v)\n",
    "            if c==0: continue\n",
    "            print(i, c)  # 1->2 is subject, 3->4 is required answer(s)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Evaluation Metrics : Each instance is evaluated by comparing \n",
    "    the tokens in the labeled answer set with those of the predicted span. \n",
    "    Precision is the true positive count divided by the number of times the system returned a non-null answer. \n",
    "    Recall is the true positive count divided by the number of instances that have an answer.\n",
    "    \"\"\"\n",
    "    \"\"\"  NOT HANDLED\n",
    "    We ignore word order, case, punctuation, and articles (\u201ca\u201d, \u201can\u201d, \u201cthe\u201d). \n",
    "    We also ignore \u201cand\u201d, which often appears when a single span captures multiple correct answers\n",
    "    (e.g. \u201cUnited States and Canada\u201d).    \n",
    "    \"\"\"\n",
    "    \n",
    "    have_ans = 1 if len(targ_a_arr)>0 else 0\n",
    "    \n",
    "    tp=0.\n",
    "    non_null=0\n",
    "\n",
    "    # Let's see if this naive method works (at all)\n",
    "    a_start_best = np.argmax(pred[3,:])\n",
    "    a_end_best   = np.argmax(pred[4,:])\n",
    "    if a_start_best<a_end_best: # This appears to be a valid guess\n",
    "        non_null=1 # The system thinks it found something\n",
    "        \n",
    "        # Work out the overlap between (a_start_best,a_end_best) and (targ_a_arr)\n",
    "        #targ_mask = np.zeros(targ.shape)\n",
    "        #for (i,j) in targ_a_arr:\n",
    "        #    for k in range(i,j+1):\n",
    "        #        targ_mask[k]=1\n",
    "        #targ\n",
    "        \n",
    "        # Work out the overlap between (a_start_best,a_end_best) and each element of (targ_a_arr)\n",
    "        best_overlap=0.\n",
    "        a0, a1 = a_start_best, a_end_best\n",
    "        for (b0, b1) in targ_a_arr:\n",
    "            intersection = min(a1, b1) - max(a0, b0)\n",
    "            union        = max(a1, b1) - min(a0, b0)\n",
    "            overlap_fraction = intersection/float(union)\n",
    "            \n",
    "            if overlap_fraction>0. and best_overlap<overlap_fraction:\n",
    "                best_overlap=overlap_fraction\n",
    "        tp = best_overlap\n",
    "        \n",
    "    else:  # Could we have guessed some other way?\n",
    "        pass\n",
    "    \n",
    "    return tp, non_null, have_ans\n",
    "\n",
    "# idx=0 should be a None, idx=1 should have an Answer, 6 seems correct\n",
    "idx=6; assess( preds[idx, 0, :, :], targs[idx, 0, :] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_tot, non_null_tot, have_ans_tot = 0.,0,0\n",
    "for idx in range(preds.shape[0]):\n",
    "    #print(\"idx=\", idx)\n",
    "    tp, non_null, have_ans = assess( preds[idx, 0, :, :], targs[idx, 0, :] )\n",
    "    print(\"       #%d assessment :tp=%.1f, non_null=%1d, have_ans=%1d\" % (idx, tp, non_null, have_ans,) )\n",
    "    tp_tot += tp\n",
    "    non_null_tot += non_null\n",
    "    have_ans_tot += have_ans\n",
    "\n",
    "precis = tp_tot / non_null_tot\n",
    "recall = tp_tot / have_ans_tot\n",
    "\n",
    "f1 = 2. * (precis*recall)/(precis+recall)\n",
    "\n",
    "print(\"precision=%.2f%% recall=%.2f%% F1=%.2f%%\" % (100.*precis, 100.*recall, 100.*f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paper (BEAT THIS!)\n",
    "# precision=43.61% recall=36.45% F1=39.61%\n",
    "\n",
    "#test.1_all.hdf5_base.npz \n",
    "# precision=30.97% recall=33.06% F1=31.98%\n",
    "\n",
    "#test.1_all.hdf5_fac1.0.npz \n",
    "# precision=24.67% recall=43.13% F1=31.39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
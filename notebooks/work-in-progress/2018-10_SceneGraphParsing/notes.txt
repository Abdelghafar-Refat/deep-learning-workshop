
Image Retrieval using Scene Graphs  (2015)
  Justin Johnson; Ranjay Krishna; Michael Stark; 
    Li-Jia Li; David A. Shamma; Michael S. Bernstein; Li Fei-Fei
  https://hci.stanford.edu/publications/2015/scenegraphs/JohnsonCVPR2015.pdf
  https://cs.stanford.edu/people/jcjohns/cvpr15_supp/

Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations  (2016)
  Ranjay Krishna; Yuke Zhu; Oliver Groth; Justin Johnson; Kenji Hata; Joshua Kravitz; Stephanie Chen; Yannis Kalantidis; 
    Li-Jia Li; David A. Shamma; Michael S. Bernstein; Li Fei-Fei
  Ranjay Krishna et al 2016
  https://arxiv.org/abs/1602.07332
  
Scene Graph Parsing as Dependency Parsing
  https://arxiv.org/pdf/1803.09189.pdf
  https://github.com/Yusics/bist-parser/tree/sgparser
  https://yusics.github.io/#about
  

Multiple objective XYZ?
  Structure SVM ?


PyTorch graph NNs (or DeepMind TF/sonnet library?)
  Graph Infomax?
  

-----------

maincard_10937 :: Visually grounded interaction and language
  https://nips2018vigil.github.io/
  https://cmt3.research.microsoft.com/VIGIL2018
  November 1st 2018 (Final Decisions : November 8th, 2018, first 20 accepted workshop papers only to get tickets - 1 each)
    ** Has potential (ideas stage)


*  Learning to match sentences with graphs
   +  Better groundtruth annotator for "Scene Graph Parsing as Dependency Parsing"
      -  Current Oracle gets only 70% F1 on the actual data
      -  Current best dependency-tree sentence parser idea -> graph gets 50%
      -  So bigger win may be in refining the annotator
      @inproceedings{wang2018sgparser,     
        title={Scene Graph Parsing as Dependency Parsing},  
        author={Wang, Yu-Siang and Liu, Chenxi and Zeng, Xiaohui and Yuille, Alan},  
        booktitle={NAACL},  
        year={2018}
      } 
      
-----------


cd ../2018-10_SceneGraphParsing
#git clone https://github.com/Yusics/bist-parser.git
git clone https://github.com/mdda/bist-parser.git
cd bist-parser
git branch -a  # list the branches
git checkout sgparser
git branch

#Split Visual Genome image_data, all_region_graphs, all_attributes into 10 pieces, 
#  and named these files x_%num, where x={image_data, all_region_graphs, all_attributes} and num={0..9}. 
#  (The size for the every first 9 pieces is all_region_graph.size()/10) and put them into preprocess/. 
#  The reason to split to 10 pieces is for acclerating the preprocessing speed.

# NB : version 1.4 has 'ground truth' synsets for objects and relationships and is "Cleaner"
#   Which versions did the sgparser paper use?

# https://visualgenome.org/  # Using version 1.2 (2016-08-29)
mkdir -p data/visual-genome
cd data/visual-genome

wget https://visualgenome.org/static/data/dataset/image_data.json.zip     #   1.7Mb
wget https://visualgenome.org/static/data/dataset/region_graphs.json.zip  # 316Mb
wget https://visualgenome.org/static/data/dataset/attributes.json.zip     #  79Mb

unzip image_data.json.zip     #   17Mb expanded
unzip region_graphs.json.zip  # 2783Mb expanded 
unzip attributes.json.zip     #  462Mb expanded



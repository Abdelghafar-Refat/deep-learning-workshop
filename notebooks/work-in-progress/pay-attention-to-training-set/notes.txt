*  Meta-Learning workshop ?
   +  http://metalearning.ml/#schedule
      -  Submission deadline: 17 October 2018 (Anywhere on Earth)
      -  Notification: 23 November 2018
      -  Camera ready: 3 December 2018
      -  Workshop: 8 December 2018  (Saturday)
   +  Tiny ImageNet (default course project for Stanford CS231N)
      -  https://tiny-imagenet.herokuapp.com/ : also : https://www.kaggle.com/c/tiny-imagenet/data
         *  train.images.zip 194.08 MB
      -  Tiny Imagenet has 200 classes. 
      -  Each class has 500 training images, 50 validation images, and 50 test images. 
      -  Training and validation sets with labels, images and bounding boxes. 
      -  Only class label to be predicted.  Test labels not released.
   +  Pick top-k using pretrained network
   +  Then fine-train a meta-learned network to differentiate between the top-k (a mini-batch-worth?)
      -  What does this actually mean?
      -  The search for the top-k has produced a list of images with similar logits to the test image
      -  But these images probably have different classes (up to k different ones)
      -  Want to create a new model (meta-learned) that distinguishes between *classes* based on the logits
      -  Loss for the meta-learned model could be :
         *  Regular cross-entropy (between k examples and their class labels) after n-optimiser-steps
            -  to avoid renumbering the labels, use real ones.  
            -  Except it might just learn to do 'argmax'
            -  OTOH, the argmax position information is somewhat factored into the search step already
            -  So, perhaps the meta-learner could just build a refined model (like the SVM step in 'my' transfer learning)
         *  Have a pair-wise comparison model, and train it to learn the co-occurrence matrix in only n-steps
            -  Then pair-wise compare the test vector vs all the searched ones, and vote...
            -  Possibly make loss dependent on final scoring rather than exclusively co-occurrence matrix fidelity
   +  Use that to raise 70-80s top-1 to 90s top-n (?)
      -  Problem: All images are really tiny, and so many mistakes are 'understandable'

   +  Useful repos
      -  ** Tiny ImageNet evaluaton server
         *  Data download : http://cs231n.stanford.edu/tiny-imagenet-200.zip
         *  https://tiny-imagenet.herokuapp.com/
         
      -  ** Success in Kaggle Tiny ImageNet (83.3% = 2nd place) 
         *  Had to restructure the original folders to fit Keras' standard ingestion
         *  Fine-tuned pre-trained Xception network
            *  Just expands small images to regular size using load_img(target_size=())
            *  Freeze first 20 layers  :: for layer in pre_trained_model.layers[:20]:  layer.trainable = False
            *  Load model with (include_top=False, pooling='avg') + Dense(200, softmax) on top
            *  Augmentations : ... /blob/master/train_with_Xception.py#L72
         *  https://github.com/ShehabMMohamed/TinyImageNet-KaggleCompetition
         
      -  ** Handle PyTorch DataSet for original data  (MIT)
         *  https://github.com/leemengtaiwan/tiny-imagenet
            *  Augmentations : ... /blob/master/tiny-imagenet.ipynb
            
      -  ** Pretrained xception for PyTorch  (BSD3)
         *  https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/xception.py 
            
      -  Fine tuned a pre-trained net, Google's InceptionV3 on the Tiny ImageNet dataset
         *  No LICENSE file
         *  https://github.com/nexus-kgp/transfer-learning-inception-v3
      -  Misc experiments
         *  No LICENSE file
         *  https://github.com/ZoeYUU/Tiny_ImageNet_Challenge
      -  Kaggle competition page
         *  Not clear that this is identical to the real thing
         *  https://www.kaggle.com/c/tiny-imagenet/data




Set-up:
git clone https://github.com/mdda/deep-learning-workshop.git

PROJECTBASE=deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set
cd ${PROJECTBASE}

wget http://cs231n.stanford.edu/tiny-imagenet-200.zip  # Length: 248100043 (237M) [application/zip]
unzip tiny-imagenet-200.zip 
rm tiny-imagenet-200.zip 

# now have BASE/tiny-imagenet-200/
## drwxrwxr-x.   3 andrewsm andrewsm    4096 Dec 12  2014 test
## drwxrwxr-x. 202 andrewsm andrewsm    4096 Dec 12  2014 train
## drwxrwxr-x.   3 andrewsm andrewsm    4096 Dec 12  2014 val
## -rw-rw-r--.   1 andrewsm andrewsm    2000 Feb  9  2015 wnids.txt
## -rw-------.   1 andrewsm andrewsm 2655750 Feb  9  2015 words.txt

ls -l tiny-imagenet-200/train/ | wc
#    201    1802   12010   # 200 class directories
ls -l tiny-imagenet-200/train/n02415577/images/ | wc
#    501    4502   34401   # Each class has 500 images in it

ls -l tiny-imagenet-200/val/images/ | wc
#  10001   90002  638902   # 10000 validation images

head tiny-imagenet-200/val/val_annotations.txt 
# val_0.JPEG	n03444034	0	32	44	62
# val_1.JPEG	n04067472	52	55	57	59
# val_2.JPEG	n04070727	4	0	60	55

ls -l tiny-imagenet-200/test/images/ |wc
#  10001   90002  648902   # Lots of images


# Now fine-tune an xception model 
#   Model downloaded : 91,674,713 bytes
# Ensure you're in a virtualenv that has python3 and pytorch, torchvision installed
#  Also probably a good idea to do this within a ```screen```

python train_xception.py # Defaults already set for a complete run of 50 epochs 
# P100 1 epoch=1324sec = 22mins, so 50epochs = 18hrs

python train_xception.py --checkpoint=./checkpoints/model_xception_latest.pth --epoch=2

python train_xception.py --checkpoint=./checkpoints/model_xception_0002.pth  # Updated version contains optimizer state and epoch number

export INSTANCE_NAME="rdai-tts-p100-vm"  # As above
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints/model_xception_0035-preserve.pth checkpoints/
# This achieves ~3.5Mb/s to download 158Mb
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints/model_xception_0052.pth checkpoints/

# Try again, using reduceonplateau - to get ~77.55% validation set accuracy
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints-04-sgd-reduceonplateau/model_xception_0021.pth ./checkpoints-04-sgd-reduceonplateau/
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth ./checkpoints-04-sgd-reduceonplateau/


python score_model.py --model=xception --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth
#   Score acc: 77.58

python train_xception.py --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth --save_trainvalues=./tiny-imagenet-200_trainval.pth
# Max GPU RAM : 6257Mb (95% usage for Titan X Maxwell)
# Time used to generate features 861.8secs

python train_judge.py --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth --trainvalues=./tiny-imagenet-200_trainval.pth



TODO: 
-----

DONE : Try different Optimizers : (Adam=poor, compared to SGD with momentum)
DONE : Try different LR-schedulers : (LRStep difficult to judge.  ReduceOnPlateau may make most sense)

DONE : Move model-xception-fine definition code to xception.py
DONE : TZ-aware estimates of finish time

DONE : Create a model evaluation script
DONE : Test downloaded checkpoint score(s)

DONE : Convert all training images to features

DONE : Check a few validation image logits to prove that similar images are retrieved ::
NB: Should ignore first column as (likely) it contains the training datapoint itself

Target=130, Found : +0.56->130, +0.55->130, +0.52->130, +0.48->130, +0.47->130, +0.46-> 36, +0.46->110, +0.44->130, +0.43->130, +0.43->110, +0.43->130, +0.42->141, +0.42->130, +0.42->141, +0.42->130, +0.42-> 36
Target= 82, Found : +0.73-> 82, +0.50-> 82, +0.48-> 82, +0.48-> 82, +0.46-> 82, +0.42-> 82, +0.41-> 82, +0.40-> 82, +0.40-> 82, +0.40-> 82, +0.40-> 82, +0.40-> 82, +0.39-> 82, +0.39-> 82, +0.39-> 82, +0.38-> 82
Target=189, Found : +0.72->189, +0.71->189, +0.71->189, +0.71->189, +0.70->189, +0.70->189, +0.69->189, +0.69->189, +0.69->189, +0.69->189, +0.68->189, +0.68->189, +0.68->189, +0.67->189, +0.67->189, +0.67->189
Target=147, Found : +0.69->147, +0.43->155, +0.40->155, +0.38->135, +0.38-> 89, +0.38-> 87, +0.38-> 87, +0.37->127, +0.37-> 87, +0.37-> 87, +0.37->155, +0.36->147, +0.36->155, +0.36->116, +0.36->155, +0.34->155
Target=130, Found : +0.68->130, +0.51->104, +0.46->104, +0.45->191, +0.45->130, +0.44->191, +0.43->130, +0.42->191, +0.41->191, +0.41->191, +0.41->130, +0.40->191, +0.40->191, +0.39->191, +0.39->191, +0.39->191
Target= 84, Found : +0.48-> 40, +0.46->  1, +0.43-> 44, +0.43->  1, +0.43->  1, +0.43->  1, +0.43-> 71, +0.42-> 71, +0.42->195, +0.42-> 95, +0.42->195, +0.42->  1, +0.42-> 71, +0.42->  1, +0.41->  1, +0.41-> 14
Target=187, Found : +0.93->187, +0.63->186, +0.62->186, +0.62->187, +0.61->187, +0.61->186, +0.60->187, +0.59->187, +0.59->187, +0.59->187, +0.59->187, +0.59->186, +0.59->186, +0.58->187, +0.58->187, +0.58->186
Target=134, Found : +0.66->134, +0.57->134, +0.52->134, +0.52->134, +0.52->134, +0.51->134, +0.49->134, +0.49->134, +0.48-> 85, +0.47-> 14, +0.47->119, +0.47->149, +0.47->  6, +0.46-> 85, +0.46->149, +0.46->149
Target=116, Found : +1.00->116, +0.72->116, +0.71->116, +0.69->116, +0.68->116, +0.67->116, +0.67->116, +0.66->116, +0.66->116, +0.66->116, +0.66->116, +0.66->116, +0.66->116, +0.66->116, +0.65->116, +0.65->116
Target= 34, Found : +1.00-> 34, +0.67-> 34, +0.67-> 34, +0.67-> 34, +0.67-> 34, +0.66-> 34, +0.65-> 34, +0.62-> 34, +0.62-> 34, +0.60-> 34, +0.60-> 34, +0.59-> 34, +0.59-> 34, +0.59-> 34, +0.59-> 34, +0.59-> 34
Target= 14, Found : +0.92-> 14, +0.78-> 14, +0.71-> 14, +0.69->134, +0.69-> 14, +0.67-> 14, +0.66-> 14, +0.65-> 14, +0.64-> 14, +0.64-> 14, +0.64-> 14, +0.64-> 14, +0.64-> 14, +0.63-> 14, +0.63-> 14, +0.62-> 14
Target= 67, Found : +0.44-> 67, +0.38->151, +0.37-> 22, +0.37->198, +0.36-> 87, +0.35->167, +0.35->198, +0.34->167, +0.34-> 67, +0.34-> 96, +0.33-> 66, +0.33-> 11, +0.33-> 66, +0.33-> 87, +0.32-> 67, +0.32-> 87
Target=169, Found : +0.83->169, +0.51->169, +0.49->169, +0.49-> 61, +0.48->169, +0.47->169, +0.47->169, +0.46->169, +0.46->169, +0.46->169, +0.45->169, +0.44->169, +0.44->169, +0.44->169, +0.43->169, +0.43->169
Target= 27, Found : +0.87-> 27, +0.57-> 27, +0.55-> 27, +0.54-> 27, +0.53-> 27, +0.53-> 26, +0.52-> 27, +0.52-> 27, +0.52-> 27, +0.52-> 27, +0.51-> 27, +0.51-> 27, +0.50-> 26, +0.50-> 26, +0.50-> 27, +0.50-> 27
Target= 68, Found : +0.77-> 68, +0.57-> 68, +0.57-> 68, +0.55-> 68, +0.53-> 68, +0.53-> 68, +0.52-> 68, +0.51-> 68, +0.51-> 68, +0.51-> 68, +0.51-> 68, +0.50-> 68, +0.50-> 68, +0.50-> 68, +0.50-> 68, +0.49-> 68
Target= 71, Found : +1.00-> 71, +0.70-> 71, +0.70-> 71, +0.69-> 71, +0.69-> 71, +0.68-> 71, +0.65-> 71, +0.65-> 71, +0.64-> 71, +0.64-> 71, +0.64-> 71, +0.63-> 71, +0.63-> 71, +0.62-> 71, +0.62-> 71, +0.62-> 71
Target=164, Found : +0.75->164, +0.69->164, +0.67->164, +0.67->164, +0.67->164, +0.66->164, +0.66->164, +0.65->164, +0.65->164, +0.64->164, +0.64->164, +0.64->164, +0.63->164, +0.63->164, +0.63->164, +0.63->164
Target= 84, Found : +1.00-> 84, +0.61-> 84, +0.60-> 84, +0.60-> 84, +0.59-> 84, +0.54-> 84, +0.54-> 84, +0.54-> 84, +0.53-> 84, +0.53-> 84, +0.52-> 84, +0.51-> 84, +0.49-> 84, +0.47-> 84, +0.47-> 84, +0.45-> 84
Target= 95, Found : +0.82-> 95, +0.66-> 95, +0.66-> 95, +0.64-> 95, +0.64-> 95, +0.63-> 95, +0.63-> 95, +0.62-> 95, +0.62-> 95, +0.62-> 95, +0.60-> 95, +0.60-> 95, +0.60-> 95, +0.58-> 95, +0.57-> 95, +0.57-> 95
Target= 40, Found : +0.82-> 40, +0.67-> 40, +0.66-> 40, +0.65-> 40, +0.64-> 40, +0.64-> 40, +0.64-> 40, +0.63-> 40, +0.63-> 40, +0.62-> 40, +0.62-> 40, +0.61-> 40, +0.61-> 40, +0.61-> 40, +0.61-> 40, +0.60-> 40
Target= 68, Found : +0.46-> 68, +0.41-> 68, +0.41-> 68, +0.41-> 68, +0.39-> 68, +0.39-> 36, +0.39-> 68, +0.38-> 68, +0.38-> 36, +0.37-> 36, +0.36-> 68, +0.36-> 68, +0.36-> 68, +0.36-> 68, +0.36-> 68, +0.36-> 68
Target= 26, Found : +1.00-> 26, +0.82-> 26, +0.80-> 26, +0.79-> 26, +0.78-> 26, +0.78-> 26, +0.78-> 26, +0.78-> 26, +0.78-> 26, +0.77-> 26, +0.77-> 26, +0.77-> 26, +0.76-> 26, +0.76-> 26, +0.76-> 26, +0.76-> 26
Target=194, Found : +0.63-> 83, +0.63-> 92, +0.61->109, +0.58->156, +0.58-> 83, +0.58-> 83, +0.57-> 83, +0.56-> 95, +0.56->116, +0.56-> 92, +0.56->129, +0.56-> 83, +0.55-> 83, +0.55-> 71, +0.55-> 83, +0.54-> 95
Target=199, Found : +0.88->199, +0.69->199, +0.61->183, +0.61->199, +0.60->199, +0.58->199, +0.57->199, +0.56->183, +0.54->199, +0.54->183, +0.54->183, +0.53->199, +0.53->199, +0.53-> 39, +0.53->199, +0.52->199
Target=117, Found : +0.94->117, +0.59->117, +0.53->117, +0.51->117, +0.51->117, +0.50->117, +0.50->117, +0.48->117, +0.47->155, +0.46->117, +0.44->117, +0.43->117, +0.43->117, +0.43->117, +0.42->136, +0.42->117
Target= 27, Found : +1.00-> 27, +0.70-> 27, +0.67-> 27, +0.63-> 27, +0.61-> 27, +0.61-> 27, +0.60-> 27, +0.59-> 27, +0.57-> 27, +0.55-> 27, +0.54-> 27, +0.54-> 27, +0.53-> 27, +0.52-> 27, +0.52-> 27, +0.52-> 29
Target= 79, Found : +0.60-> 79, +0.49-> 79, +0.47-> 79, +0.47-> 79, +0.45-> 79, +0.44->162, +0.44-> 79, +0.43-> 79, +0.42-> 79, +0.41-> 14, +0.41-> 79, +0.41-> 79, +0.40-> 79, +0.39-> 79, +0.39-> 14, +0.38->162
Target= 89, Found : +0.85-> 89, +0.58-> 89, +0.53-> 89, +0.52-> 89, +0.51-> 89, +0.49-> 89, +0.49-> 89, +0.49-> 89, +0.49-> 89, +0.47-> 89, +0.47-> 89, +0.47-> 89, +0.47-> 89, +0.47-> 89, +0.47-> 89, +0.47-> 89
Target=128, Found : +0.68->128, +0.65->128, +0.58->128, +0.56->128, +0.55->128, +0.55->128, +0.54-> 86, +0.54->128, +0.54->128, +0.53->128, +0.53->128, +0.53-> 86, +0.52->128, +0.52->128, +0.51->128, +0.51->128
Target= 17, Found : +0.89-> 17, +0.46-> 46, +0.46->  1, +0.43-> 46, +0.43-> 17, +0.42-> 46, +0.41-> 46, +0.41->  1, +0.41->  4, +0.41->  1, +0.40->  1, +0.40->  1, +0.40-> 17, +0.40-> 46, +0.40->  1, +0.40-> 46
Target=137, Found : +0.60->137, +0.46->137, +0.41->137, +0.40->137, +0.39-> 61, +0.39->137, +0.37->133, +0.37->137, +0.37->129, +0.37->137, +0.37->137, +0.37->137, +0.37->129, +0.36-> 86, +0.36->137, +0.36->137
Target= 54, Found : +1.00-> 54, +0.62-> 54, +0.58-> 54, +0.52-> 54, +0.52->152, +0.50->152, +0.47->152, +0.46->152, +0.45->152, +0.44->152, +0.42-> 67, +0.42->152, +0.42->152, +0.42->152, +0.42->152, +0.41-> 54




New training loop to train a 16-channel logit analysis tool to 'do better' than the regular network on 'test image' logits

New meta-training loop to train a model that learns to classify the 16 examples more firmly, and then gets applied to 'test image' logits

? Check a few validation image network random projections to prove that similar images are retrieved


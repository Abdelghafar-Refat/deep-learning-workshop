*  Meta-Learning workshop ?
   +  http://metalearning.ml/#schedule
      -  Submission deadline: 17 October 2018 (Anywhere on Earth)
      -  Notification: 23 November 2018
      -  Camera ready: 3 December 2018
      -  Workshop: 8 December 2018  (Saturday)
   +  Tiny ImageNet (default course project for Stanford CS231N)
      -  https://tiny-imagenet.herokuapp.com/ : also : https://www.kaggle.com/c/tiny-imagenet/data
         *  train.images.zip 194.08 MB
      -  Tiny Imagenet has 200 classes. 
      -  Each class has 500 training images, 50 validation images, and 50 test images. 
      -  Training and validation sets with labels, images and bounding boxes. 
      -  Only class label to be predicted.  Test labels not released.
   +  Pick top-k using pretrained network
   +  Then fine-train a meta-learned network to differentiate between the top-k (a mini-batch-worth?)
      -  What does this actually mean?
      -  The search for the top-k has produced a list of images with similar logits to the test image
      -  But these images probably have different classes (up to k different ones)
      -  Want to create a new model (meta-learned) that distinguishes between *classes* based on the logits
      -  Loss for the meta-learned model could be :
         *  Regular cross-entropy (between k examples and their class labels) after n-optimiser-steps
            -  to avoid renumbering the labels, use real ones.  
            -  Except it might just learn to do 'argmax'
            -  OTOH, the argmax position information is somewhat factored into the search step already
            -  So, perhaps the meta-learner could just build a refined model (like the SVM step in 'my' transfer learning)
         *  Have a pair-wise comparison model, and train it to learn the co-occurrence matrix in only n-steps
            -  Then pair-wise compare the test vector vs all the searched ones, and vote...
            -  Possibly make loss dependent on final scoring rather than exclusively co-occurrence matrix fidelity
   +  Use that to raise 70-80s top-1 to 90s top-n (?)
      -  Problem: All images are really tiny, and so many mistakes are 'understandable'

   +  Useful repos
      -  ** Tiny ImageNet evaluaton server
         *  Data download : http://cs231n.stanford.edu/tiny-imagenet-200.zip
         *  https://tiny-imagenet.herokuapp.com/
         
      -  ** Success in Kaggle Tiny ImageNet (83.3% = 2nd place) 
         *  Had to restructure the original folders to fit Keras' standard ingestion
         *  Fine-tuned pre-trained Xception network
            *  Just expands small images to regular size using load_img(target_size=())
            *  Freeze first 20 layers  :: for layer in pre_trained_model.layers[:20]:  layer.trainable = False
            *  Load model with (include_top=False, pooling='avg') + Dense(200, softmax) on top
            *  Augmentations : ... /blob/master/train_with_Xception.py#L72
         *  https://github.com/ShehabMMohamed/TinyImageNet-KaggleCompetition
         
      -  ** Handle PyTorch DataSet for original data  (MIT)
         *  https://github.com/leemengtaiwan/tiny-imagenet
            *  Augmentations : ... /blob/master/tiny-imagenet.ipynb
            
      -  ** Pretrained xception for PyTorch  (BSD3)
         *  https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/xception.py 
            
      -  Fine tuned a pre-trained net, Google's InceptionV3 on the Tiny ImageNet dataset
         *  No LICENSE file
         *  https://github.com/nexus-kgp/transfer-learning-inception-v3
      -  Misc experiments
         *  No LICENSE file
         *  https://github.com/ZoeYUU/Tiny_ImageNet_Challenge
      -  Kaggle competition page
         *  Not clear that this is identical to the real thing
         *  https://www.kaggle.com/c/tiny-imagenet/data




Set-up:
git clone https://github.com/mdda/deep-learning-workshop.git

PROJECTBASE=deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set
cd ${PROJECTBASE}

wget http://cs231n.stanford.edu/tiny-imagenet-200.zip  # Length: 248100043 (237M) [application/zip]
unzip tiny-imagenet-200.zip 
rm tiny-imagenet-200.zip 

# now have BASE/tiny-imagenet-200/
## drwxrwxr-x.   3 andrewsm andrewsm    4096 Dec 12  2014 test
## drwxrwxr-x. 202 andrewsm andrewsm    4096 Dec 12  2014 train
## drwxrwxr-x.   3 andrewsm andrewsm    4096 Dec 12  2014 val
## -rw-rw-r--.   1 andrewsm andrewsm    2000 Feb  9  2015 wnids.txt
## -rw-------.   1 andrewsm andrewsm 2655750 Feb  9  2015 words.txt

ls -l tiny-imagenet-200/train/ | wc
#    201    1802   12010   # 200 class directories
ls -l tiny-imagenet-200/train/n02415577/images/ | wc
#    501    4502   34401   # Each class has 500 images in it

ls -l tiny-imagenet-200/val/images/ | wc
#  10001   90002  638902   # 10000 validation images

head tiny-imagenet-200/val/val_annotations.txt 
# val_0.JPEG	n03444034	0	32	44	62
# val_1.JPEG	n04067472	52	55	57	59
# val_2.JPEG	n04070727	4	0	60	55

ls -l tiny-imagenet-200/test/images/ |wc
#  10001   90002  648902   # Lots of images


# Now fine-tune an xception model 
#   Model downloaded : 91,674,713 bytes
# Ensure you're in a virtualenv that has python3 and pytorch, torchvision installed
#  Also probably a good idea to do this within a ```screen```

python train_xception.py # Defaults already set for a complete run of 50 epochs 
# P100 1 epoch=1324sec = 22mins, so 50epochs = 18hrs

python train_xception.py --checkpoint=./checkpoints/model_xception_latest.pth --epoch=2

python train_xception.py --checkpoint=./checkpoints/model_xception_0002.pth  # Updated version contains optimizer state and epoch number

export INSTANCE_NAME="rdai-tts-p100-vm"  # As above
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints/model_xception_0035-preserve.pth checkpoints/
# This achieves ~3.5Mb/s to download 158Mb
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints/model_xception_0052.pth checkpoints/

# Try again, using reduceonplateau - to get ~77.55% validation set accuracy
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints-04-sgd-reduceonplateau/model_xception_0021.pth ./checkpoints-04-sgd-reduceonplateau/
gcloud compute scp $INSTANCE_NAME:~/deep-learning-workshop/notebooks/work-in-progress/pay-attention-to-training-set/checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth ./checkpoints-04-sgd-reduceonplateau/


python score_model.py --model=xception --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth
#   Score acc: 77.58

python train_xception.py --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth --save_trainvalues=./tiny-imagenet-200_trainval.pth
# Max GPU RAM : 6257Mb (95% usage for Titan X Maxwell)
# Time used to generate features 861.8secs

python train_judge.py --checkpoint=./checkpoints-04-sgd-reduceonplateau/model_xception_0038.pth --trainvalues=./tiny-imagenet-200_trainval.pth



TODO: 
-----

DONE : Try different Optimizers : (Adam=poor, compared to SGD with momentum)
DONE : Try different LR-schedulers : (LRStep difficult to judge.  ReduceOnPlateau may make most sense)

DONE : Move model-xception-fine definition code to xception.py
DONE : TZ-aware estimates of finish time

DONE : Create a model evaluation script
DONE : Test downloaded checkpoint score(s)

DONE : Convert all training images to features

DONE : Check a few validation image logits to prove that similar images are retrieved ::
DONE : Check that x_hat=(x-means)/norm means that x_hat is now mean==0 and stdev==1


Training Set - training_transforms
------------------------------------
Target=160, Found : 160, 160, 160, 160, 160, 160, 160, 193,  83, 160, 160, 160, 160, 160, 160, 160, Weights: +1.00, +0.48, +0.48, +0.46, +0.46, +0.46, +0.45, +0.45, +0.45, +0.45, +0.44, +0.44, +0.44, +0.43, +0.43, +0.43
Target= 13, Found :  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13, Weights: +1.00, +0.74, +0.71, +0.70, +0.70, +0.69, +0.68, +0.68, +0.68, +0.67, +0.66, +0.66, +0.66, +0.66, +0.65, +0.65
Target=129, Found : 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, 129, Weights: +1.00, +0.61, +0.61, +0.60, +0.60, +0.59, +0.59, +0.58, +0.58, +0.57, +0.57, +0.57, +0.57, +0.56, +0.56, +0.56
Target=149, Found : 149, 149, 149, 149, 149, 149, 149, 149, 135, 149, 149, 149, 149, 149,  73, 149, Weights: +1.00, +0.51, +0.48, +0.47, +0.42, +0.42, +0.40, +0.39, +0.38, +0.38, +0.38, +0.38, +0.38, +0.37, +0.37, +0.37
Target= 11, Found :  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11, Weights: +1.00, +0.56, +0.55, +0.54, +0.54, +0.54, +0.53, +0.53, +0.53, +0.53, +0.53, +0.53, +0.53, +0.52, +0.52, +0.52
Target=170, Found : 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, Weights: +1.00, +0.88, +0.85, +0.85, +0.84, +0.83, +0.83, +0.83, +0.82, +0.81, +0.81, +0.80, +0.80, +0.80, +0.80, +0.79
Target= 68, Found :  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68,  68, Weights: +1.00, +0.64, +0.63, +0.61, +0.61, +0.61, +0.61, +0.60, +0.60, +0.60, +0.59, +0.59, +0.59, +0.59, +0.59, +0.59
Target= 47, Found :  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47, Weights: +1.00, +0.72, +0.71, +0.70, +0.67, +0.66, +0.65, +0.65, +0.65, +0.64, +0.64, +0.64, +0.64, +0.64, +0.63, +0.63

Target= 46, Found :  46, 148, 148, 148, 148,  46, 148, 148, 148, 148, 148, 148, 148, 148,  46, 148, Weights: +1.00, +0.55, +0.54, +0.54, +0.54, +0.51, +0.51, +0.51, +0.51, +0.50, +0.50, +0.49, +0.49, +0.49, +0.49, +0.49

Target=150, Found : 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, 150, Weights: +0.66, +0.62, +0.61, +0.60, +0.59, +0.59, +0.58, +0.58, +0.57, +0.57, +0.56, +0.56, +0.56, +0.56, +0.56, +0.55
Target= 53, Found :  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53,  53, Weights: +0.84, +0.63, +0.61, +0.60, +0.60, +0.59, +0.59, +0.59, +0.59, +0.59, +0.59, +0.58, +0.58, +0.58, +0.57, +0.57
Target= 79, Found :  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79, Weights: +0.85, +0.50, +0.47, +0.45, +0.45, +0.43, +0.43, +0.43, +0.43, +0.42, +0.42, +0.42, +0.41, +0.41, +0.41, +0.41
Target= 11, Found :  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11, Weights: +0.84, +0.61, +0.57, +0.56, +0.56, +0.55, +0.55, +0.54, +0.53, +0.53, +0.53, +0.53, +0.53, +0.53, +0.53, +0.53
Target=128, Found : 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, Weights: +0.78, +0.73, +0.70, +0.70, +0.69, +0.68, +0.68, +0.67, +0.67, +0.67, +0.67, +0.67, +0.67, +0.67, +0.66, +0.66
Target= 33, Found :  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33, Weights: +0.82, +0.67, +0.65, +0.61, +0.60, +0.60, +0.59, +0.59, +0.58, +0.58, +0.57, +0.57, +0.57, +0.57, +0.56, +0.56
Target=119, Found : 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, Weights: +0.53, +0.52, +0.48, +0.48, +0.46, +0.45, +0.45, +0.45, +0.44, +0.44, +0.43, +0.43, +0.43, +0.43, +0.42, +0.41
Target=115, Found : 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 145, 115, 115, 115, Weights: +0.86, +0.54, +0.48, +0.48, +0.46, +0.45, +0.44, +0.44, +0.43, +0.43, +0.43, +0.43, +0.42, +0.42, +0.42, +0.42
Target=171, Found : 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, 171, Weights: +0.78, +0.55, +0.54, +0.54, +0.54, +0.54, +0.52, +0.51, +0.51, +0.51, +0.51, +0.51, +0.51, +0.50, +0.50, +0.50
Target=145, Found : 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, Weights: +0.77, +0.73, +0.72, +0.68, +0.68, +0.67, +0.66, +0.66, +0.65, +0.64, +0.64, +0.64, +0.63, +0.63, +0.62, +0.62
Target= 78, Found :  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78, Weights: +0.90, +0.80, +0.75, +0.75, +0.73, +0.72, +0.70, +0.70, +0.69, +0.69, +0.69, +0.68, +0.68, +0.67, +0.67, +0.66

Target=109, Found : 109, 129, 109, 109, 109,  13,  83, 113, 113, 163,  71,  13, 151, 109, 113, 113, Weights: +0.55, +0.46, +0.45, +0.43, +0.43, +0.42, +0.40, +0.40, +0.40, +0.40, +0.39, +0.39, +0.39, +0.39, +0.39, +0.39
Target= 61, Found :  61,  61,  61,  61,  61,  98, 126,  61,  61,  61,  61,  98,  61,  61,  61,  61, Weights: +0.68, +0.50, +0.49, +0.45, +0.45, +0.43, +0.43, +0.43, +0.43, +0.41, +0.41, +0.41, +0.41, +0.40, +0.40, +0.40
Target=168, Found : 106, 168, 168, 163, 168, 106, 119, 168, 142, 106, 168, 119, 131,  74, 120, 168, Weights: +0.45, +0.45, +0.44, +0.44, +0.43, +0.42, +0.41, +0.41, +0.41, +0.41, +0.40, +0.40, +0.40, +0.38, +0.38, +0.38
Target=135, Found : 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, Weights: +0.85, +0.47, +0.46, +0.45, +0.44, +0.43, +0.43, +0.42, +0.41, +0.41, +0.41, +0.41, +0.41, +0.41, +0.41, +0.40
Target= 94, Found :  94, 153,  94, 153, 153,  94, 153, 153, 153, 153, 153, 153,  94, 153, 153,  94, Weights: +0.87, +0.66, +0.65, +0.63, +0.61, +0.60, +0.60, +0.59, +0.59, +0.59, +0.58, +0.58, +0.58, +0.57, +0.57, +0.57
Target= 29, Found : 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, Weights: +0.55, +0.55, +0.53, +0.53, +0.52, +0.51, +0.51, +0.51, +0.50, +0.50, +0.49, +0.49, +0.49, +0.49, +0.49, +0.49
Target=105, Found : 105, 105, 105, 105,  85, 129, 105, 105, 105,  85, 105, 105, 105, 105, 105, 105, Weights: +0.54, +0.53, +0.53, +0.47, +0.47, +0.47, +0.46, +0.44, +0.44, +0.43, +0.43, +0.43, +0.42, +0.42, +0.42, +0.42
Target=162, Found : 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, Weights: +0.85, +0.67, +0.64, +0.63, +0.63, +0.63, +0.62, +0.62, +0.62, +0.61, +0.61, +0.61, +0.61, +0.61, +0.61, +0.61
Target= 74, Found :  74, 148,  28, 158, 158,  29, 148, 158,  74, 148,  74,  28, 158,  74, 158,  74, Weights: +0.82, +0.45, +0.44, +0.44, +0.43, +0.43, +0.43, +0.43, +0.42, +0.42, +0.42, +0.40, +0.40, +0.39, +0.38, +0.38
Target=187, Found : 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, Weights: +0.87, +0.78, +0.77, +0.77, +0.75, +0.75, +0.73, +0.73, +0.73, +0.73, +0.72, +0.71, +0.71, +0.70, +0.69, +0.69
Target=151, Found : 129, 129, 140, 129, 126, 126,  95, 129, 129, 151, 126, 126, 126, 129, 126, 126, Weights: +0.55, +0.54, +0.53, +0.53, +0.52, +0.52, +0.51, +0.50, +0.49, +0.49, +0.48, +0.48, +0.48, +0.47, +0.47, +0.47
Target=160, Found :  14, 129,  92,  14, 196,  71,   2,  92,  71,  14, 183,  83,  14,  17,  83, 104, Weights: +0.43, +0.42, +0.42, +0.41, +0.41, +0.41, +0.41, +0.40, +0.40, +0.40, +0.40, +0.40, +0.40, +0.40, +0.39, +0.39

Training Set - training_transforms (ignore first Found column)
---------------------------------------------------------------
Target=104, Found : 104, 104, 104, 104, 104, 104, 174, 104, 174, 104, 104, 104, 104, 104, 104, 174, Weights: 12->104,  3->174
Target= 16, Found :  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16, Weights: 15-> 16
Target=  4, Found :   4,   4,   4,   1,   7,   4,   4,   4,  19,   4,  19,   8,   4,   4,   7,   7, Weights:  8->  4,  3->  7,  2-> 19,  1->  8,  1->  1
Target= 57, Found :  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57,  57, Weights: 15-> 57
Target= 81, Found :  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81, Weights: 15-> 81
Target=159, Found : 159, 159, 159, 159, 159, 159, 159, 159, 117, 159, 159, 159, 159, 159, 159, 159, Weights: 14->159,  1->117
Target=181, Found : 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181,  10, 181, 181, 181, Weights: 14->181,  1-> 10
Target=145, Found : 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, Weights: 15->145
Target= 49, Found :  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49, 111,  49,  49, Weights: 14-> 49,  1->111
Target=124, Found : 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, Weights: 15->124
Target=175, Found : 175, 175, 175, 175, 175, 175, 175, 175, 104, 175,   6, 175, 175, 175, 175, 175, Weights: 13->175,  1->104,  1->  6
Target=163, Found : 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, Weights: 15->163
Target=134, Found : 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, Weights: 15->134
Target= 27, Found :  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27, Weights: 15-> 27
Target= 93, Found :  93,  93,  93,  93,  93,  93,  73, 110,  61,  93,  93,  93,  18,  93,  93,  93, Weights: 11-> 93,  1->110,  1-> 73,  1-> 61,  1-> 18
Target=170, Found : 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, Weights: 15->170
Target=125, Found : 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, Weights: 15->125
Target=127, Found : 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, Weights: 15->127
Target=163, Found : 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, 163, Weights: 15->163
Target= 83, Found :  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83,  83, Weights: 15-> 83
Target= 66, Found :  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66, Weights: 15-> 66
Target= 76, Found :  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76, Weights: 15-> 76
Target= 54, Found :  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54,  54, Weights: 15-> 54
Target= 55, Found :  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55,  55, Weights: 15-> 55

Target= 80, Found :  80,  32,  30, 134,  30,  30,  30,  80,   6,  32,  67,  30, 151,  30,  30,  60, Weights:  7-> 30,  2-> 32,  1->151,  1->134,  1-> 80,  1-> 67,  1-> 60,  1->  6
Target=156, Found : 156, 181,  85, 156, 132, 114, 100, 127, 171,  65,  65, 167,  65, 127, 180,  78, Weights:  3-> 65,  2->127,  1->181,  1->180,  1->171,  1->167,  1->156,  1->132,  1->114,  1->100,  1-> 85,  1-> 78
Target=131, Found : 131, 110, 161,   0, 161, 131, 110, 161, 151, 110, 172, 110,   0, 161, 161, 131, Weights:  5->161,  4->110,  2->131,  2->  0,  1->172,  1->151
Target=182, Found : 182, 177, 177, 177, 183, 186, 183, 178, 183, 177, 177, 182, 177, 177, 177, 177, Weights:  9->177,  3->183,  1->186,  1->182,  1->178

Target= 96, Found : 170,  92, 170, 109,  71,  92,  66, 170,  66, 170,  95, 170,  71, 116, 197,  71, Weights:  4->170,  3-> 71,  2-> 92,  2-> 66,  1->197,  1->116,  1->109,  1-> 95
Target=188, Found :  21, 122,  21,  21,  21,  95,  21, 137,  20,  21,  20, 149,  23,  23, 141,  21, Weights:  6-> 21,  2-> 23,  2-> 20,  1->149,  1->141,  1->137,  1->122,  1-> 95
Target= 96, Found :  92,  14, 109,  91, 129,  95,  52,  10, 162,  83,  83,  71, 183,  71,  14, 109, Weights:  2->109,  2-> 83,  2-> 71,  2-> 14,  1->183,  1->162,  1->129,  1-> 95,  1-> 91,  1-> 52,  1-> 10
Target= 75, Found : 154, 154,  66, 154, 154, 154, 154, 154,  78, 154, 154, 170, 154, 154, 170, 154, Weights: 11->154,  2->170,  1-> 78,  1-> 66

:: Pure voting would give us 75% top1 accuracy (vs 77% with actual classifier)
:: Looking at top1 of found (ignoring first entry) would give same


Training Set - validation_transforms (all columns valid)
---------------------------------------------------------
Target=139, Found : 139, 139, 139, 139, 139, 139, 139, 100, 122, 122, 139, 122, 139, 139, 139, Weights: 11->139,  3->122,  1->100
Target=114, Found : 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, Weights: 15->114
Target= 93, Found :  93,  93,  93,  93,  93,  93,  82,  93,  93,  93,  88,  93,  93,  93,  82, Weights: 12-> 93,  2-> 82,  1-> 88
Target=109, Found : 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 138, 109, Weights: 14->109,  1->138
Target=140, Found : 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, Weights: 15->140
Target=193, Found : 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, 193, Weights: 15->193
Target= 20, Found :  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20, Weights: 15-> 20
Target=146, Found : 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, 146, Weights: 15->146
Target= 70, Found :  70,  70,  70,  70,  70,  94,  70,  70,  70,  70,  70,  70,  70,  70,  70, Weights: 14-> 70,  1-> 94
Target= 56, Found :  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56,  56, Weights: 15-> 56
Target=  2, Found :   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2, Weights: 15->  2
Target=173, Found : 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, 173, Weights: 15->173
Target=136, Found : 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136, Weights: 15->136
Target= 99, Found :  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99,  99, Weights: 15-> 99
Target=111, Found : 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, Weights: 15->111
Target= 71, Found :  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71, Weights: 15-> 71
Target=187, Found : 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, 187, Weights: 15->187
Target=151, Found : 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, Weights: 15->151
Target= 37, Found :  37,  37,  37,  37,  37,  37,  37,  37,  37,  37,  37,  38,  37,  37,  37, Weights: 14-> 37,  1-> 38
Target= 92, Found :  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92,  92, Weights: 15-> 92
Target=162, Found : 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, 162, Weights: 15->162
Target=194, Found : 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, 194, Weights: 15->194
Target= 12, Found :  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12, Weights: 15-> 12
Target= 16, Found :  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  15, Weights: 14-> 16,  1-> 15
Target= 77, Found :  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77, Weights: 15-> 77
Target=151, Found : 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, 151, Weights: 15->151
Target= 29, Found :  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29, Weights: 15-> 29
Target= 39, Found :  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39, Weights: 15-> 39
Target=161, Found : 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, 161, Weights: 15->161
Target=190, Found : 190, 190, 190, 190, 190, 190, 190, 190, 190, 147, 190, 190, 190, 190, 190, Weights: 14->190,  1->147
Target= 16, Found :  16,  16,  16,  16,  16,  16,  34,  16,  16,  16,  16,  16,  16,  16,  16, Weights: 14-> 16,  1-> 34
Target= 78, Found :  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78, Weights: 15-> 78

:: Pure voting would give us 100% top1 accuracy (vs 77% with actual classifier)


Validation Set - validation_transforms (all columns valid)
---------------------------------------------------------
Target=107, Found : 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 111, 107, 107, Weights: 15->107,  1->111
Target= 90, Found :  90,  90,  90,  90,  90, 175,  90,  90,  90,  90,  90,  90,  90, 135,  90,  90, Weights: 14-> 90,  1->175,  1->135
Target=138, Found : 138, 138, 138, 138, 138, 138, 143, 138, 138, 143, 138, 138, 138, 143, 138, 138, Weights: 13->138,  3->143
Target= 67, Found :  67,  67,  67,  67,  67,  72,  67, 140, 138,  80,  67,  80,  67,  67,  67, 138, Weights: 10-> 67,  2->138,  2-> 80,  1->140,  1-> 72
Target=135, Found : 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, 135, Weights: 16->135
Target= 38, Found :  38,  38,  42, 183,  45,  79,  45, 183,  39, 173, 183,  44,  38, 183, 183, 183, Weights:  6->183,  3-> 38,  2-> 45,  1->173,  1-> 79,  1-> 44,  1-> 42,  1-> 39
Target= 63, Found :  63,  63, 142, 123, 142,  63,  63,  63,  63, 144,  63,  63, 144,  63,  63, 101, Weights: 10-> 63,  2->144,  2->142,  1->123,  1->101
Target=107, Found : 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, Weights: 16->107
Target= 11, Found :  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11, Weights: 16-> 11
Target= 42, Found :  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  40,  42,  42,  42, Weights: 15-> 42,  1-> 40
Target= 51, Found :  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51, Weights: 16-> 51
Target= 23, Found :  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23, Weights: 16-> 23
Target=167, Found : 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, 167, Weights: 16->167
Target= 78, Found :  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78,  78, Weights: 16-> 78
Target= 27, Found :  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27, Weights: 16-> 27
Target=170, Found : 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, 170, Weights: 16->170
Target=197, Found : 197, 194, 194, 194, 194, 194, 197, 129, 194, 194, 194, 194, 194, 197, 194, 194, Weights: 12->194,  3->197,  1->129
Target= 38, Found :  38,  38,  42,  45,  38,  38,  36,  38,  38,  39,  45, 174,  45,  38,  45,  38, Weights:  8-> 38,  4-> 45,  1->174,  1-> 42,  1-> 39,  1-> 36
Target= 71, Found :  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71,  71, Weights: 16-> 71
Target= 35, Found :  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35, Weights: 16-> 35
Target= 69, Found :  69,  69,  69,  69, 147,  69,  69,  69,  69,  69,  69,  69,  69,  69,  69,  69, Weights: 15-> 69,  1->147
Target= 51, Found :  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51,  51, Weights: 16-> 51
Target= 83, Found :  83,  83,  83,  83,  83,  83,  83, 178,  83,  83,  83,  83,  83,  83,  83,  83, Weights: 15-> 83,  1->178
Target=104, Found : 104, 104, 104, 104, 104, 104, 104, 174, 104, 104, 104, 104, 104, 104, 104, 187, Weights: 14->104,  1->187,  1->174

Target=158, Found : 158,  74,  74,  74,  74,  74,  74, 158,  74, 198,  74,  74,  74,  74,  74,  74, Weights: 13-> 74,  2->158,  1->198

Target=162, Found : 170,  66,  66,  66, 194, 194, 194, 162,  66,  66,  57,  66, 164, 170,  66,  66, Weights:  8-> 66,  3->194,  2->170,  1->164,  1->162,  1-> 57
Target=195, Found :   8, 195,   8,   8,   8,   8,   8, 195,   8,   8, 195,   8,   8,   8,   8,   8, Weights: 13->  8,  3->195
Target=134, Found :  85, 149, 149,  85,  85, 144,  85,  85,  85,  85, 134, 151, 134, 134,  85,  85, Weights:  9-> 85,  3->134,  2->149,  1->151,  1->144
Target=139, Found : 122,  40, 157,  40,  67,  64,  41, 122,  75, 199,  40, 144, 199, 168, 122,  40, Weights:  4-> 40,  3->122,  2->199,  1->168,  1->157,  1->144,  1-> 75,  1-> 67,  1-> 64,  1-> 41
Target=198, Found : 197, 197, 197, 198, 197, 197, 197,  96, 197,  96, 197, 198, 198, 157, 195, 197, Weights:  9->197,  3->198,  2-> 96,  1->195,  1->157
Target= 88, Found : 118, 118,  88,  88,  88,  88,  88, 132,  88,  88,  99,  88, 125,  88,  79,  88, Weights: 10-> 88,  2->118,  1->132,  1->125,  1-> 99,  1-> 79
Target=107, Found : 111, 195, 111, 111, 108, 176, 111,   8, 111, 111, 114, 176, 111, 111, 111, 111, Weights: 10->111,  2->176,  1->195,  1->114,  1->108,  1->  8

:: Pure voting would give us 75% top1 accuracy (vs 77% with actual classifier)



TODO 
  DONE : Should ignore first column in each group as (likely) it contains the training datapoint itself
  Check with validation transforms (top-1 should be 100% match)
  Check on validation set 
  See whether top-n logits correspond (at all) to top-n retrievals (requires model up to logit layer)
  Maybe need to get 10 of each training class from the list of 'close' classes
  Move pre-proc + attn into xception.py
  Score for picking (say) max-vote in top-16 (x first one)
  Think about subtracting/projecting x_features from all found examples (~PCA)

  ? Maybe pass back training example idx to caller

New training loop to train a 16-channel logit analysis tool to 'do better' than the regular network on 'test image' logits

New meta-training loop to train a model that learns to classify the 16 examples more firmly, and then gets applied to 'test image' logits

? Check a few validation image network random projections to prove that similar images are retrieved


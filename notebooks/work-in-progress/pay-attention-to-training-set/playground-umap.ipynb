{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See UMAP results on basic 'digits' raw image files (per documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "#print(digits.DESCR) # Documentation\n",
    "#digits.images.shape # (1797, 8, 8)\n",
    "digits.data.shape   # (1797, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "reducer.fit(digits.data)  # <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.transform(digits.data)\n",
    "# Verify that the result of calling transform is\n",
    "# idenitical to accessing the embedding_ attribute\n",
    "assert(np.all(embedding == reducer.embedding_))\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=digits.target, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP projection of the Digits dataset', fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See UMAP results on plain MNIST raw image files\n",
    "\n",
    "*  https://github.com/snakers4/playing_with_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install Pillow-SIMD  # Hmm : Missing jpeg library..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "mnist_data = torchvision.datasets.MNIST('./data/mnist', download=True, \n",
    "  train=True, transform=transform, )\n",
    "mnist_data_test = torchvision.datasets.MNIST('./data/mnist', download=True, \n",
    "  train=False, transform=transform, )\n",
    "\n",
    "data_set = mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=40  # Also works for CNN training below\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "  data_set, batch_size=batch_size, #shuffle=True,\n",
    "  num_workers=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dim = 50\n",
    "\n",
    "proj = torch.nn.Linear( 28*28, proj_dim )  # Does the initialisation 'better' than torch.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the basic dataset\n",
    "xs, ys = np.zeros( (len(data_set), 28*28) ), np.zeros( (len(data_set),) )\n",
    "for i_batch, (x_batch, y_batch) in enumerate(data_loader):\n",
    "    x_batch_flat = x_batch.view(-1, 28*28)\n",
    "    xs[i_batch*batch_size:(i_batch+1)*batch_size, :] = x_batch_flat.detach()\n",
    "    ys[i_batch*batch_size:(i_batch+1)*batch_size] = y_batch.detach()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This maps the result of the projection directly into the results numpy arrays\n",
    "def map_data_via_proj(ds, d_loader):\n",
    "    x_arr, y_arr = np.zeros( (len(ds), proj_dim) ), np.zeros( (len(ds),) )\n",
    "    for i_batch, (x_batch, y_batch) in enumerate(d_loader):\n",
    "        x_batch_flat = x_batch.view(-1, 28*28)\n",
    "        \n",
    "        x_proj = proj( x_batch_flat )\n",
    "        #print(x_proj.size()); break\n",
    "\n",
    "        x_arr[i_batch*batch_size:(i_batch+1)*batch_size, :] = x_proj.detach()\n",
    "        y_arr[i_batch*batch_size:(i_batch+1)*batch_size] = y_batch.detach()    \n",
    "    return x_arr, y_arr\n",
    "    \n",
    "xs_proj, ys_proj = map_data_via_proj(data_set, data_loader)\n",
    "xt_proj, yt_proj = map_data_via_proj(mnist_data_test, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_batch*batch_size\n",
    "base=59990; ys[base+0:base+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "reducer_proj = umap.UMAP(random_state=42)\n",
    "reducer_proj.fit(xs_proj) \n",
    "print(\"Fitting %d-D took %d secs\" % (proj_dim, time.time()-t0,) )  \n",
    "# 400d : 74 secs\n",
    "# 100d : 76 secs \n",
    "#  50d : 69 secs\n",
    "#  35d : 68 secs\n",
    "#  20d : 68 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_proj = reducer_proj.transform(xs_proj)\n",
    "embedding_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embedding_proj[:, 0], embedding_proj[:, 1], c=ys_proj, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP %d-D projection of raw MNIST images' % (proj_dim,), fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train CNN on dataset (with labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so now let's build a CNN to classify regular MNIST \n",
    "#   with last layer being 50D, and re-run the UMAP on that result...\n",
    "\n",
    "# Shout out to https://github.com/floydhub/mnist/blob/master/main.py for\n",
    "#   basic layout of model - updated significantly here for 0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv1_mp = torch.nn.MaxPool2d(2)\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_mp = torch.nn.MaxPool2d(2)\n",
    "        self.conv2_drop = torch.nn.Dropout2d()\n",
    "        self.fc1 = torch.nn.Linear(320, 50)\n",
    "        self.drop = torch.nn.Dropout()\n",
    "        self.fc2 = torch.nn.Linear(50, 10)\n",
    "        self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x, middle_layer=False):\n",
    "        x = self.relu(self.conv1_mp(self.conv1(x)))\n",
    "        x = self.relu(self.conv2_mp(self.conv2_drop(self.conv2(x))))\n",
    "        x = x.view(-1, 320) # Flatten\n",
    "        x = self.fc1(x)\n",
    "        if middle_layer:\n",
    "            return x\n",
    "        x = self.drop(self.relu(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.logsoftmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  data_set, batch_size=batch_size, #shuffle=True,\n",
    "  num_workers=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % (10000//batch_size) == 0:\n",
    "            print('Train Epoch: {} [{:5d}/{:5d} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just use the test dataset to evaluate our model\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  mnist_data_test, batch_size=batch_size, #shuffle=True,\n",
    "  num_workers=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0., 0\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    test_loss += loss_fn(output, target).item() # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the indices of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum().numpy()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    correct * 100. / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do UMAP on the final hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This maps the result of the projection directly into the results numpy arrays\n",
    "def map_data_via_cnn(ds, d_loader):\n",
    "    x_arr, y_arr = np.zeros( (len(ds), proj_dim) ), np.zeros( (len(ds),) )\n",
    "    model.eval()\n",
    "    for i_batch, (x_batch, y_batch) in enumerate(d_loader):\n",
    "        data = x_batch.to(device)\n",
    "        output = model(data, middle_layer=True)\n",
    "        x_cnn = output.cpu().detach().numpy()\n",
    "        x_arr[i_batch*batch_size:(i_batch+1)*batch_size, :] = x_cnn\n",
    "        y_arr[i_batch*batch_size:(i_batch+1)*batch_size] = y_batch.detach()\n",
    "    return x_arr, y_arr\n",
    "\n",
    "xs_cnn, ys_cnn = map_data_via_cnn(data_set, data_loader)\n",
    "xt_cnn, yt_cnn = map_data_via_cnn(mnist_data_test, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "reducer_cnn = umap.UMAP(random_state=42)\n",
    "reducer_cnn.fit(xs_cnn) \n",
    "print(\"Fitting %d-D to CNN middle layer took %d secs\" % (proj_dim, time.time()-t0,) )  \n",
    "# 50d : 70 secs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cnn = reducer_cnn.transform(xs_cnn)\n",
    "embedding_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "# Other potential colormaps : Spectral, tab10, tab20, tab20b?, terrain, jet\n",
    "plt.scatter(embedding_cnn[:, 0], embedding_cnn[:, 1], c=ys_cnn, cmap='Spectral', s=5) \n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title('UMAP %d-D CNN middle layer for MNIST' % (proj_dim,), fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "*  Start with a (small) set of known-labels from the training set\n",
    "   +   Pass them through the fixed straight UMAP, and the CNN UMAP\n",
    "   +   Work out test-set error based on nearest neighbours\n",
    "   +   Figure out which training set member(s) would be best to know the labels of...\n",
    "       -   Maybe a Gaussian Optimisation thing?\n",
    "*  Later (soon after), train the CNN until it gets 'good' training set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(ys==ys_cnn)  These are identical => data_loader arrives in consistent order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get a small list of indices of data from each class\n",
    "labelled_idx = []\n",
    "for c in range(10):  # num_classes\n",
    "    #idx_c = np.where(ys==c)[0][0]\n",
    "    idx_c = np.nonzero(ys==c)[0][0]\n",
    "    labelled_idx.append(idx_c)\n",
    "labelled_idx, ys[labelled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do a KNN-style classification across a test set\n",
    "#   http://scikit-learn.org/stable/modules/neighbors.html#finding-the-nearest-neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def test_knn(reducer, idx, x_arr, y_arr, x_test, y_test):\n",
    "    # Convert the labelled points to the embedding, and prepare the knn\n",
    "    x_known, y_known = x_arr[idx], y_arr[idx]\n",
    "    emb_known = reducer.transform(x_known)\n",
    "    #print(emb_known, y_known)  # Makes sense\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(emb_known)\n",
    "    \n",
    "    # Go through test set:\n",
    "    emb_test = reducer.transform(x_test)\n",
    "    near_dists, near_idxs = nbrs.kneighbors(emb_test)  # measures to known label points\n",
    "    #near_dist = near_dists[:,0]\n",
    "    near_idx = near_idxs[:,0]\n",
    "    #print(near_dist, near_idx)\n",
    "    \n",
    "    # So let's get the classes corresponding to the nearest neighbours\n",
    "    classes = y_known[near_idx]\n",
    "    #print(y_test, classes.tolist())\n",
    "    \n",
    "    # Count the correct classifications\n",
    "    accuracy = np.sum(y_test==classes)/classes.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_knn(reducer_proj, labelled_idx, xs_proj, ys_proj, xt_proj[0:10], yt_proj[0:10])\n",
    "test_knn(reducer_proj, labelled_idx, xs_proj, ys_proj, xt_proj, yt_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_knn(reducer_cnn, labelled_idx, xs_cnn, ys_cnn, xt_cnn, yt_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_next_knn(reducer, idx, x_arr, y_arr):\n",
    "    # Convert the labelled points to the embedding, and prepare the knn\n",
    "    x_known, y_known = x_arr[idx], y_arr[idx]\n",
    "    emb_known = reducer.transform(x_known)\n",
    "    #print(emb_known, y_known)  # Makes sense\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(emb_known)\n",
    "    \n",
    "    # Go through training set:\n",
    "    emb_all = reducer.transform(x_arr)\n",
    "    near_dists, near_idxs = nbrs.kneighbors(emb_all)  # measures to known label points\n",
    "    #near_dist = near_dists[:,0]\n",
    "    #near_idx = near_idxs[:,0]\n",
    "    #print(near_dist, near_idx)\n",
    "    \n",
    "    # We are interested in : \n",
    "    #   Points where dist[0]>0 (i.e. not known), and class[0]!=class[1] (may be confused)\n",
    "    #     ?ranked by  ( dist[1] - dist[0] )  (i.e. near a boundary)\n",
    "    #     ?ranked by  ( dist[0] )  (i.e. far from their nearest determiner)\n",
    "    \n",
    "    near_class0 = y_known[ near_idxs[:,0] ]\n",
    "    near_class1 = y_known[ near_idxs[:,1] ]\n",
    "    \n",
    "    importance_if_different = np.where(near_class0 == near_class1, 0., \n",
    "                                       #near_dists[:,1] - near_dists[:,0])\n",
    "                                       near_dists[:,0])  # Closest point is furthest away\n",
    "    \n",
    "    # Now return the indices that are most important to know\n",
    "    important_index = np.argmax(importance_if_different)\n",
    "    return important_index\n",
    "\n",
    "    #important_indices = np.argsort(importance_if_different)[-n:]\n",
    "    #return important_indices\n",
    "\n",
    "def best_next_knns(reducer, idx, x_arr, y_arr, n=10):\n",
    "    idx_new = idx.copy()\n",
    "    \n",
    "    for i in range(n):\n",
    "        idx_want = best_next_knn(reducer_proj, idx_new, xs_proj, ys_proj)\n",
    "        # let's assume we find out this label now...\n",
    "        idx_new.append(idx_want)\n",
    "    \n",
    "    return idx_new\n",
    "\n",
    "important_idx = best_next_knns(reducer_proj, labelled_idx, xs_proj, ys_proj, n=10)\n",
    "important_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_idx = best_next_knn(reducer_proj, labelled_idx, xs_proj, ys_proj, n=8)\n",
    "#important_idx = best_next_knn(reducer_proj, labelled_idx, xs_proj, ys_proj, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embedding_proj[:, 0], embedding_proj[:, 1], c=ys_proj, cmap='Spectral', s=5)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "plt.scatter(embedding_proj[labelled_idx, 0], embedding_proj[labelled_idx, 1], marker='^', s=200)\n",
    "extra_idx = important_idx[len(labelled_idx):]\n",
    "plt.scatter(embedding_proj[extra_idx, 0], embedding_proj[extra_idx, 1], marker='v', s=200)\n",
    "\n",
    "plt.title('UMAP %d-D projection of raw MNIST images' % (proj_dim,), fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_idx = important_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Ideas\n",
    "\n",
    "*  Investigate what the UMAP 'reducer' and 'embeddings' are doing\n",
    "   +   What does the embedding represent? \n",
    "   +   Is the embedding usable in its own right?\n",
    "*  Train MNIST but leave several digits out\n",
    "   +   Look at where they would lie in UMAP space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "*  \"Feature Affinity based Pseudo Labeling for Semi-supervised Person Re-identification\"\n",
    "    +   https://arxiv.org/pdf/1805.06118.pdf\n",
    "*  PyTorch CUDA KNN\n",
    "    +   https://github.com/shaibagon/pytorch_knn_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
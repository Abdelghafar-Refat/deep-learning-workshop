{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Sizing for Keras CNN Model Zoo\n",
    "\n",
    "This is a sanity check for : https://culurciello.github.io/tech/2016/06/04/nets.html\n",
    "\n",
    "In particular, their model comparison graph :\n",
    "\n",
    "![model comparison graph](./images/presentation/ImageNet-model-comparison_726x458.png)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "targz = \"v0.5.tar.gz\"\n",
    "url = \"https://github.com/fchollet/deep-learning-models/archive/\"+targz\n",
    "models_orig_dir = 'deep-learning-models-0.5'\n",
    "models_here_dir = 'keras_deep_learning_models'\n",
    "models_dir = './models/'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "    tarfilepath = os.path.join(models_dir, targz)\n",
    "    if not os.path.isfile(tarfilepath):\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve(url, tarfilepath) \n",
    "    import tarfile, shutil\n",
    "    tarfile.open(tarfilepath, 'r:gz').extractall(models_dir)\n",
    "    shutil.move(os.path.join(models_dir, models_orig_dir), os.path.join(models_dir, models_here_dir))\n",
    "    if os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "        os.unlink(tarfilepath)\n",
    "\n",
    "sys.path.append(models_dir)\n",
    "\n",
    "print(\"Keras Model Zoo model code installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "if keras.__version__ < '2.0.0':\n",
    "    print(\"keras version = %s is too old\" % (keras.__version__,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_deep_learning_models.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image as keras_preprocessing_image\n",
    "\n",
    "# This call to 'decode_predictions' wiil potentially download imagenet_class_index.json (35Kb)\n",
    "decode_predictions(np.zeros( (1,1000) ), top=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Image Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_sanity(model, img_path, img_class_str=''):\n",
    "    img = keras_preprocessing_image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    predictions = decode_predictions(preds, top=1)\n",
    "    \n",
    "    if len(img_class_str)>0:\n",
    "        if predictions[0][0][1] != img_class_str:\n",
    "            print(\"INCORRECT CLASS!\")\n",
    "        print('Predicted:', predictions)\n",
    "        # prints: [[('n02123045', 'tabby', 0.76617092)]]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path, img_class = './images/cat-with-tongue_224x224.jpg', 'tabby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading / timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def load_model_weights(fn, weight_set, assume_download=30):\n",
    "    t0 = time.time()\n",
    "    m = fn(weights=weight_set)\n",
    "    if time.time()-t0>float(assume_download): # more that this => downloading, so retry to get set-up time cleanly\n",
    "        print(\"Assume that >30secs means that we just downloaded the dataset : load again for timing\")        \n",
    "        t0 = time.time()\n",
    "        m = fn(weights=weight_set)\n",
    "    trainable_count = int(np.sum([keras.backend.count_params(p) for p in set(m.trainable_weights)]))\n",
    "    fixed_count = int(np.sum([keras.backend.count_params(p) for p in set(m.non_trainable_weights)]))\n",
    "    print(\"Loaded %.3fMM parameters (and %.0fK fixed parameters) into model in %.3f seconds\" % \n",
    "          (trainable_count/1000000., fixed_count/1000., float(time.time()-t0),))\n",
    "    return m, trainable_count, fixed_count\n",
    "\n",
    "def time_model_predictions(model, img_path, batch_size=1, iters=1):\n",
    "    img = keras_preprocessing_image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    batch = np.tile(x, (batch_size,1,1,1))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(iters):\n",
    "        _ = model.predict(batch,  batch_size=batch_size)\n",
    "        \n",
    "    single = float(time.time()-t0)*1000./iters/batch_size\n",
    "    print(\"A single image forward pass takes %.0f ms (in batches of %d, average of %d passes)\" % \n",
    "          (single, batch_size, iters,))\n",
    "    return single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50\n",
    "\n",
    "http://felixlaumon.github.io/2015/01/08/kaggle-right-whale.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_deep_learning_models.resnet50 import ResNet50\n",
    "\n",
    "#model_resnet50 = ResNet50(weights='imagenet')\n",
    "model_resnet50 = load_model_weights(ResNet50, 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_sanity(model_resnet50, img_path, img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_model_predictions(model_resnet50, img_path, batch_size=8, iters=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls -lh ~/.keras/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```99M resnet50_weights_tf_dim_ordering_tf_kernels.h5```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
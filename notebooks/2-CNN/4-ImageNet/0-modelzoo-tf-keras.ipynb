{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Sizing for Keras CNN Model Zoo\n",
    "\n",
    "This is a sanity check for : https://culurciello.github.io/tech/2016/06/04/nets.html\n",
    "\n",
    "In particular, their model comparison graph :\n",
    "\n",
    "![model comparison graph](./images/presentation/ImageNet-model-comparison_726x458.png)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "targz = \"v0.5.tar.gz\"\n",
    "url = \"https://github.com/fchollet/deep-learning-models/archive/\"+targz\n",
    "models_orig_dir = 'deep-learning-models-0.5'\n",
    "models_here_dir = 'keras_deep_learning_models'\n",
    "models_dir = './models/'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "    tarfilepath = os.path.join(models_dir, targz)\n",
    "    if not os.path.isfile(tarfilepath):\n",
    "        import urllib.request \n",
    "        urllib.request.urlretrieve(url, tarfilepath) \n",
    "    import tarfile, shutil\n",
    "    tarfile.open(tarfilepath, 'r:gz').extractall(models_dir)\n",
    "    shutil.move(os.path.join(models_dir, models_orig_dir), os.path.join(models_dir, models_here_dir))\n",
    "    if os.path.isfile( os.path.join(models_dir, models_here_dir, 'README.md') ):\n",
    "        os.unlink(tarfilepath)\n",
    "\n",
    "sys.path.append(models_dir)\n",
    "\n",
    "print(\"Keras Model Zoo model code installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "if keras.__version__ < '2.0.0':\n",
    "    print(\"keras version = %s is too old\" % (keras.__version__,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras_deep_learning_models.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras_deep_learning_models.imagenet_utils import decode_predictions\n",
    "from keras.preprocessing import image as keras_preprocessing_image\n",
    "\n",
    "# This call to 'decode_predictions' wiil potentially download imagenet_class_index.json (35Kb)\n",
    "decode_predictions(np.zeros( (1,1000) ), top=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Image Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_input(model, preprocess_input_fn, img_path):\n",
    "    target_size=model.input_shape[1:]\n",
    "    img = keras_preprocessing_image.load_img(img_path, target_size=target_size)\n",
    "    \n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input_fn(x)\n",
    "    return x\n",
    "\n",
    "def test_model_sanity(model, preprocess_input_fn, img_path, img_class_str=''):\n",
    "    x = image_to_input(model, preprocess_input_fn, img_path)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    predictions = decode_predictions(preds, top=1)\n",
    "    \n",
    "    if len(img_class_str)>0:\n",
    "        if predictions[0][0][1] != img_class_str:\n",
    "            print(\"INCORRECT CLASS!\")\n",
    "        print('Predicted:', predictions)\n",
    "        # prints: [[('n02123045', 'tabby', 0.76617092)]]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path, img_class = './images/cat-with-tongue_224x224.jpg', 'tabby'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading / timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def load_model_weights(fn, weight_set, assume_download=30):\n",
    "    t0 = time.time()\n",
    "    m = fn(weights=weight_set)\n",
    "    if time.time()-t0>float(assume_download): # more that this => downloading, so retry to get set-up time cleanly\n",
    "        print(\"Assume that >30secs means that we just downloaded the dataset : load again for timing\")        \n",
    "        t0 = time.time()\n",
    "        m = fn(weights=weight_set)\n",
    "    time_load = float(time.time()-t0)\n",
    "    weight_count=[ float(np.sum([keras.backend.count_params(p) for p in set(w)]))/1000./1000. \n",
    "                   for w in [m.trainable_weights, m.non_trainable_weights] ]\n",
    "    print(\"Loaded %.0fMM parameters (and %.0fk fixed parameters) into model in %.3f seconds\" % \n",
    "          (weight_count[0], weight_count[1]*1000., time_load,))\n",
    "    return m, time_load, weight_count[0], weight_count[1]\n",
    "\n",
    "def time_model_predictions(model, preprocess_input_fn, img_path, batch_size=1, iters=1):\n",
    "    x = image_to_input(model, preprocess_input_fn, img_path)\n",
    "\n",
    "    batch = np.tile(x, (batch_size,1,1,1))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(iters):\n",
    "        _ = model.predict(batch,  batch_size=batch_size)\n",
    "        \n",
    "    single = float(time.time()-t0)*1000./iters/batch_size\n",
    "    print(\"A single image forward pass takes %.0f ms (in batches of %d, average of %d passes)\" % \n",
    "          (single, batch_size, iters,))\n",
    "    return single\n",
    "\n",
    "def total_summary(fn, preprocess_input_fn):\n",
    "    model, time_setup, trainable, fixed = load_model_weights(fn, 'imagenet')\n",
    "    test_model_sanity(model, preprocess_input_fn, img_path, img_class)\n",
    "    time_iter_ms = time_model_predictions(model, preprocess_input_fn, img_path, batch_size=8, iters=2)\n",
    "    model=None # Clean up\n",
    "    keras.backend.clear_session()\n",
    "    return dict(name=fn.__name__, \n",
    "                params_trainable=trainable, params_fixed=fixed, \n",
    "                time_setup=time_setup, time_iter_ms=time_iter_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worked Example : ResNet 50\n",
    "\n",
    "http://felixlaumon.github.io/2015/01/08/kaggle-right-whale.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras_deep_learning_models.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#model_resnet50 = ResNet50(weights='imagenet')\n",
    "model_resnet50,_,_,_ = load_model_weights(ResNet50, 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model_sanity(model_resnet50, preprocess_input, img_path, img_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = time_model_predictions(model_resnet50, preprocess_input, img_path, batch_size=8, iters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_resnet50=None           # release 'pointers'\n",
    "keras.backend.clear_session() # release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default is NOT to evaluate these...  remove the '#' to enable\n",
    "evaluate = ['VGG16', 'InceptionV3', 'ResNet50', ]\n",
    "stats_arr=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'VGG16' in evaluate:\n",
    "    from keras_deep_learning_models.vgg16 import VGG16, preprocess_input\n",
    "    stats_arr.append( total_summary( VGG16, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'InceptionV3' in evaluate:\n",
    "    from keras_deep_learning_models.inception_v3 import InceptionV3, preprocess_input\n",
    "    stats_arr.append( total_summary( InceptionV3, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'ResNet50' in evaluate:\n",
    "    from keras_deep_learning_models.resnet50 import ResNet50, preprocess_input\n",
    "    stats_arr.append( total_summary( ResNet50, preprocess_input ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = { s['name']:s for s in stats_arr }\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Default Stats as a fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(stats_arr)==0:\n",
    "    stats={\n",
    "        'VGG16':      { 'params_fixed': 0.0,    'params_trainable': 138.,\n",
    "                        'time_iter_ms': 735.,'time_setup':  3.7},\n",
    "        'InceptionV3':{ 'params_fixed': 0.03443,'params_trainable':  23.8,\n",
    "                        'time_iter_ms': 550.,'time_setup': 19.6},\n",
    "        'ResNet50':   { 'params_fixed': 0.05312,'params_trainable':  25.5,\n",
    "                        'time_iter_ms': 524.,'time_setup': 16.5},\n",
    "    }\n",
    "    stats_simlim={\n",
    "        'VGG16':      { 'params_fixed': 0.0,    'params_trainable': 138.,\n",
    "                        'time_iter_ms': 343.,'time_setup': 1.37},\n",
    "        'InceptionV3':{ 'params_fixed': 0.03443,'params_trainable': 23.8,\n",
    "                        'time_iter_ms': 225.,'time_setup': 4.11},\n",
    "        'ResNet50':   { 'params_fixed': 0.05312,'params_trainable': 25.5,\n",
    "                        'time_iter_ms': 209.,'time_setup': 2.96},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph (v. different axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('image processing time (ms)')\n",
    "ax.set_ylabel('# of parameters')\n",
    "\n",
    "X,Y,R,names=[],[],[],[]\n",
    "for name, data in stats.items():\n",
    "    X.append(data['time_iter_ms'])\n",
    "    Y.append(data['params_trainable']+data['params_fixed'])\n",
    "    R.append(data['time_setup']*10.)\n",
    "    names.append(name)\n",
    "ax.scatter(X, Y, s=R)\n",
    "\n",
    "for name,x,y in zip(names, X, Y):\n",
    "    plt.annotate(\n",
    "        name, xy=(x, y), xytext=(+0, 30),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls -lh ~/.keras/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 35K Apr 19 01:20 imagenet_class_index.json\n",
    " 92M Apr 19 23:40 inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
    " 99M Apr 19 01:16 resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
    "528M Apr 19 22:26 vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "http://joelouismarino.github.io/blog_posts/blog_googlenet_keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
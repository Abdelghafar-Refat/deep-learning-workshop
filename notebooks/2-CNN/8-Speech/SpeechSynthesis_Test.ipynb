{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc  # for image resizing\n",
    "\n",
    "#import scipy.io.wavfile\n",
    "\n",
    "# pip install soundfile librosa python_speech_features\n",
    "import soundfile\n",
    "\n",
    "from IPython.display import Audio as audio_playback_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = './data/raw-from-phone.wav'  # un-normalized\n",
    "f = './data/num_phone_en-UK_m_Martin14.wav'  # has been normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the original file\n",
    "samples, sample_rate = soundfile.read(f)\n",
    "\n",
    "samples = samples / np.max(samples)  # Norm the signal\n",
    "\n",
    "def show_waveform(sound):\n",
    "    n_samples = sound.shape[0]\n",
    "\n",
    "    plt.figure(figsize=(12,2))\n",
    "    plt.plot(np.arange(0.0, n_samples)/sample_rate, sound)\n",
    "    plt.xticks( np.arange(0.0, n_samples/sample_rate, 0.5), rotation=90 )\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_waveform(samples)\n",
    "audio_playback_widget(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 512\n",
    "\n",
    "fft_step   = 0.010 # 10ms\n",
    "fft_window = 0.025 # 25ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "#hop_length=int(fft_step*sample_rate)   # number audio of frames between STFT columns\n",
    "#win_length=int(fft_window*sample_rate) # number audio of frames between STFT columns\n",
    "\n",
    "win_length=None # defaults to n_fft\n",
    "hop_length=None # defaults to win_length/4\n",
    "\n",
    "spectrum_complex = librosa.stft(samples, n_fft=n_fft, \n",
    "                       hop_length=hop_length, win_length=win_length,\n",
    "                       window='hann', center=True, \n",
    "                       dtype=np.complex64) # This has real and imaginary parts each as float32\n",
    "\n",
    "spectrum_complex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_defft = librosa.istft(spectrum_complex, \n",
    "                              hop_length=hop_length, win_length=win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_view_and_play(stub, samples_here, show_waveform_graph=True):\n",
    "    f = './tmp/%s.wav' % (stub,)\n",
    "    soundfile.write(f, samples_here/np.max(samples_here), samplerate=sample_rate)\n",
    "    if show_waveform_graph:\n",
    "        show_waveform(samples_here)\n",
    "    return audio_playback_widget(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This proves that audio->sfft(complex)->defft(complex)->audio is pretty much identical\n",
    "quick_view_and_play('defft', samples_defft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_real = np.absolute(spectrum_complex)\n",
    "# effectively, all phase information==0\n",
    "\n",
    "samples_re_defft = librosa.istft(spectrum_real, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "# This has a strange 'phasing effect' (as might be expected...)\n",
    "quick_view_and_play('re-defft', samples_re_defft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectrum( spectrum, title='Spectrum' ):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "\n",
    "    cax = ax.matshow(spectrum, interpolation='nearest', aspect='auto', cmap=plt.cm.afmhot, origin='lower')\n",
    "    fig.colorbar(cax)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "show_spectrum( np.log(spectrum_real), title='Spectrum (Absolute value)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def real_spectrum_to_samples( spectrum_re, iters=20 ):\n",
    "    # Initially pick random phases\n",
    "    phases = 2.0 * np.pi * np.random.random_sample(spectrum_re.shape) - np.pi\n",
    "    #phases = np.zeros_like( spectrum_re )\n",
    "\n",
    "    for i in range(iters):\n",
    "        spectrum_complex_guess = spectrum_re * np.exp(1.j*phases)\n",
    "\n",
    "        samples_reim = librosa.istft(spectrum_complex_guess, \n",
    "                                     hop_length=hop_length, win_length=win_length,\n",
    "                                     window='hann', center=True, \n",
    "                                    )\n",
    "\n",
    "        re_calc_fft = librosa.stft(samples_reim, n_fft=n_fft, \n",
    "                         hop_length=hop_length, win_length=win_length,\n",
    "                         window='hann', center=True, \n",
    "                         dtype=np.complex64)\n",
    "\n",
    "        phases_next = np.angle( re_calc_fft )  # What are the phases just reported?  Next iteration, use these\n",
    "        #phases = (phases+phases_next)/2.0\n",
    "        \n",
    "        # Find the phase difference in the range (-pi, +pi)\n",
    "        phases_diff = (phases_next - phases + np.pi) % (2 * np.pi ) - np.pi\n",
    "        \n",
    "        phases_clipped = np.clip( phases_diff, a_min=-np.pi/8.0, a_max=+np.pi/8.0)\n",
    "        phases = phases + phases_clipped\n",
    "        \n",
    "        print( [ '%+.4f' % p for p in phases_clipped[30:40, int(5.3/fft_step)] ] )\n",
    "        #print( np.abs(phases_diff).mean() )\n",
    "        \n",
    "    return samples_reim\n",
    "    \n",
    "samples_reim_defft = real_spectrum_to_samples( spectrum_real )\n",
    "\n",
    "quick_view_and_play('reim-defft', samples_reim_defft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features\n",
    "n_mel_freq_components = 64\n",
    "#n_mel_freq_components = 256\n",
    "\n",
    "# create_mel_filters\n",
    "#mel_inversion_filter = python_speech_features.get_filterbanks(nfft=n_fft, samplerate=sample_rate,\n",
    "#                                        nfilt=n_mel_freq_components,\n",
    "#                                        lowfreq = 300.0, highfreq = 8000.0)\n",
    "#                                        #lowfreq = 0, highfreq = None)\n",
    "#\n",
    "#mel_filter = mel_inversion_filter.T / mel_inversion_filter.sum(axis=1)\n",
    "#mel_filter.shape\n",
    "\n",
    "mel_filters_from_fft = python_speech_features.get_filterbanks(nfft=n_fft, samplerate=sample_rate,\n",
    "                                        nfilt=n_mel_freq_components,\n",
    "                                        #lowfreq = 10.0, highfreq = None)\n",
    "                                        #lowfreq = 300.0, highfreq = 8000.0)\n",
    "                                        #lowfreq = 10, highfreq = None)\n",
    "                                                    )\n",
    "\n",
    "#mel_filters_from_fft = np.identity( 257 ) # This is uncompressed : just as a check\n",
    "\n",
    "mel_filters_from_fft.shape   # (64, 257)\n",
    "mel_filters_from_fft[10:15,10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_filters_from_fft[15,:]\n",
    "#mel_filters_from_fft.sum(axis=0)  # Total attention paid to each of the FFT bins\n",
    "mel_filters_from_fft.sum(axis=1)  # Amount of FFT contribution to each mel bin\n",
    "\n",
    "# To share out the weight in a given mel bin, need to scale it down\n",
    "mel_filters_to_fft = (mel_filters_from_fft / mel_filters_from_fft.sum(axis=1, keepdims=True)).T\n",
    "#mel_filters_psuedoinverse\n",
    "\n",
    "spectrum_identity = mel_filters_to_fft.dot(mel_filters_from_fft)  # Should be ~I(257,257)\n",
    "#spectrum_identity[5:10, 5:10] # demonstrates identity and some smear at low frequencies\n",
    "spectrum_identity[27:35, 27:35] # demonstrates 'smear' but not over/under emphasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mel(spectrogram, mel_filter_from_fft, shorten_factor=1.0):\n",
    "    #spectrogram = np.square(spectrogram)    # Convert to 'power' ?\n",
    "    mel_spec = mel_filter_from_fft.dot( spectrogram )\n",
    "    \n",
    "    mel_spec = scipy.ndimage.zoom(mel_spec.astype('float32'), \n",
    "                                   [1, 1./shorten_factor],  # Shorten in time direction\n",
    "                                   mode='nearest', order=1,\n",
    "                                 ).astype('float32')\n",
    "    #print(np.min(mel_spec), np.max(mel_spec), )\n",
    "    \n",
    "    #mel_spec_bounded = np.clip(mel_spec, a_min=np.exp(-15.0), a_max=None)\n",
    "    return mel_spec #_bounded\n",
    "\n",
    "def mel_to_spectrogram(mel_spec, mel_filter_to_fft, shorten_factor=1.0):\n",
    "    \"\"\"\n",
    "    takes in an mel spectrogram and returns a normal spectrogram for inversion \n",
    "    \"\"\"\n",
    "    mel_spec_uncompressed = scipy.ndimage.zoom(mel_spec.astype('float32'), \n",
    "                                               #[shorten_factor,1], \n",
    "                                               [1, shorten_factor], \n",
    "                                               mode='nearest', order=1,\n",
    "                                              ).astype('float32')\n",
    "\n",
    "    spectrum_recovered = mel_filter_to_fft.dot( mel_spec_uncompressed )\n",
    "    \n",
    "    #uncompressed_spec = uncompressed_spec -4\n",
    "    \n",
    "    #spectrum_recovered = np.sqrt( spectrum_recovered )  # Convert from 'power'\n",
    "    \n",
    "    return np.clip(spectrum_recovered, a_min=np.exp(-12.0), a_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_factor=1.0  # This is a time-wise compression factor : 1.0 is none\n",
    "#shorten_factor=4.0  # This is a time-wise compression factor : 4.0 seems harsh\n",
    "\n",
    "mel_spec = make_mel(spectrum_real, mel_filters_from_fft, shorten_factor=shorten_factor)\n",
    "\n",
    "#spectrum_real\n",
    "mel_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the compressed spec\n",
    "show_spectrum( np.log(mel_spec), 'mel Spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_from_mel = mel_to_spectrogram(mel_spec, mel_filters_to_fft, shorten_factor=shorten_factor)\n",
    "#spectrogram_from_mel = spectrum_identity.dot(spectrum_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the recovered spec\n",
    "show_spectrum( np.log(spectrogram_from_mel), 'Recovered Spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is the original 'real' one, for comparison \n",
    "#show_spectrum( np.log( np.clip(spectrum_real, a_min=np.exp(-12.0), a_max=None)), title='Original Spectrum' )\n",
    "show_spectrum( np.log( spectrum_real ), title='Original Spectrum' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_via_mel = real_spectrum_to_samples( spectrogram_from_mel, iters=20 )\n",
    "\n",
    "quick_view_and_play('via-mel', samples_via_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['+0.0027', '+0.0111', '+0.0081', '+0.0105', '+0.0106', '+0.0172', '+0.0040', '+0.0095', '+0.0237', '+0.0258']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Turn mp3 into mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "librosa.__version__  # '0.5.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_in = './librivox/guidetomen_02_rowland_64kb.mp3'\n",
    "filename_out = filename_in.replace('.mp3', '.mel')\n",
    "\n",
    "#import audioread\n",
    "#with audioread.audio_open(filename) as f:\n",
    "#    print(f.channels, f.samplerate, f.duration)#print(os.listdir(f))\n",
    "\n",
    "# Requires 'dnf install ffmpeg' for .mp3 decoding\n",
    "\n",
    "#samples, sample_rate = librosa.core.load(filename_in, sr=None)\n",
    "samples, sample_rate = librosa.core.load(filename_in, sr=24000)\n",
    "samples = samples/np.max(samples)  # Force amplitude of waveform into range ~-1 ... +1.0\n",
    "\n",
    "sample_rate, samples.shape, samples.shape[0]/sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick_view_and_play('librivox-orig', samples) # Rather large computation for this graph...\n",
    "audio_playback_widget(filename_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_step   = 12.5/1000. # 12.5ms\n",
    "fft_window = 50.0/1000.  # 50ms\n",
    "\n",
    "n_fft = 512*4\n",
    "\n",
    "hop_length = int(fft_step*sample_rate)\n",
    "win_length = int(fft_window*sample_rate)\n",
    "\n",
    "n_mels = 80\n",
    "fmin = 125 # Hz\n",
    "#fmax = ~8000\n",
    "\n",
    "hop_length, win_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html\n",
    "#S = librosa.feature.melspectrogram(y=samples, sr=sample_rate, n_mels=n_mels, fmin=fmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_complex = librosa.stft(samples, n_fft=n_fft, \n",
    "                       hop_length=hop_length, \n",
    "                       win_length=win_length, window='hann', )\n",
    "\n",
    "power_spectra = np.abs(spectra_complex)**2\n",
    "melspectra = librosa.feature.melspectrogram(S=power_spectra, n_mels=n_mels, fmin=fmin)\n",
    "\n",
    "spectra_complex.shape, melspectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(librosa)\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(melspectra[:,0:1024], ref=np.max), \n",
    "                         y_axis='mel', fmin=125, x_axis='time', \n",
    "                         hop_length=hop_length, sr=sample_rate)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.show()\n",
    "# Section Two Of ... The Guide to Men ,,, This Librivox recording is in the Public Domain ...\n",
    "# Bachelors ... Somehow ... Just at the psychological moment when a bachelor fancies he's going to die (etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspectra.min(), melspectra.max(), melspectra.mean(), melspectra.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??  Is the following appropriate for us?\n",
    "#melspectra_floored = np.maximum(0.01, melspectra)\n",
    "melspectra_floored = np.maximum(0.001, melspectra)\n",
    "\n",
    "melout = np.log(melspectra_floored)\n",
    "melout.min(), melout.max(), melout.mean(), melout.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(melout[:, 0:1024], y_axis='mel', fmin=125, x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_dictionary = dict(\n",
    "    sample_rate=sample_rate, \n",
    "    hop_length=hop_length, win_length=win_length,\n",
    "    fmin=fmin, \n",
    "    mel=melout,\n",
    ")\n",
    "\n",
    "pickle.dump(data_dictionary, open(filename_out, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Created dataset : %s\" % (filename_out, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting, in that it allows vector-valued (x,y) with various penalty term choices  :\n",
    "# https://librosa.github.io/librosa/generated/librosa.core.dtw.html#librosa-core-dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the inverse operation on spectra_complex... and listen to it\n",
    "samples_defft = librosa.istft(spectra_complex, hop_length=hop_length, win_length=win_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_view_and_play('librivox-recreated', samples_defft, show_waveform_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_just_amplitudes = np.abs(spectra_complex) # + 0.j\n",
    "samples_defft_real = librosa.istft(spectra_just_amplitudes, hop_length=hop_length, win_length=win_length)\n",
    "quick_view_and_play('librivox-recreated-poorly', samples_defft_real, show_waveform_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build dataset from a series of mp3 files\n",
    "\n",
    "For each file in turn, pull out blocks of spectra each 1024 spectra long (~12sec).\n",
    "First 64 of these will be discarded, so 'step increment' should be (1024-64=960)\n",
    "Ignore tail block.\n",
    "\n",
    "https://medium.com/@chengweizhang2012/an-easy-guide-to-build-new-tensorflow-datasets-and-estimator-with-keras-model-9b0f6b4c1b0d\n",
    "\n",
    "https://github.com/Tony607/Keras_catVSdog_tf_estimator/blob/master/keras_estimator_vgg16-cat_vs_dog-TFRecord.ipynb\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/datasets\n",
    "\n",
    "http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "\n",
    "https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import librosa\n",
    "librosa.__version__  # '0.5.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate= 24000 # input will be standardised to this rate\n",
    "\n",
    "fft_step   = 12.5/1000. # 12.5ms\n",
    "fft_window = 50.0/1000.  # 50ms\n",
    "\n",
    "n_fft = 512*4\n",
    "\n",
    "hop_length = int(fft_step*sample_rate)\n",
    "win_length = int(fft_window*sample_rate)\n",
    "\n",
    "n_mels = 80\n",
    "fmin = 125 # Hz\n",
    "#fmax = ~8000\n",
    "\n",
    "win_length, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And for the training windowing :\n",
    "steps_total, steps_leadin = 1024, 64\n",
    "\n",
    "# Test the flatten idea\n",
    "#a = np.array([3.4, 55.4, 34.23])\n",
    "a = np.array([[3.4, 55.4,],[34.23, 342.1221]])\n",
    "a.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List( value=[value] ))\n",
    "def _floats_feature(np_arr):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList( value=np_arr.flatten().tolist() ))\n",
    "\n",
    "def convert_wavs_to_spectra_learnable_records(filename_in):\n",
    "    filename_base = filename_in.replace('.mp3', '_%s.tfrecords')\n",
    "\n",
    "    samples, _sample_rate = librosa.core.load(filename_in, sr=sample_rate)\n",
    "    samples = samples/np.max(samples)  # Force amplitude of waveform into range ~-1 ... +1.0\n",
    "\n",
    "    spectra_complex = librosa.stft(samples, n_fft=n_fft, \n",
    "                       hop_length=hop_length, \n",
    "                       win_length=win_length, window='hann', )\n",
    "\n",
    "    power_spectra = np.abs(spectra_complex)**2\n",
    "    melspectra = librosa.feature.melspectrogram(S=power_spectra, n_mels=n_mels, fmin=fmin)\n",
    "\n",
    "    with tf.python_io.TFRecordWriter(filename_base % ('train',)) as writer_train, \\\n",
    "         tf.python_io.TFRecordWriter(filename_base % ('valid',)) as writer_valid, \\\n",
    "         tf.python_io.TFRecordWriter(filename_base % ('test',)) as writer_test :\n",
    "                \n",
    "        # Ok, now create a series of Examples with these features\n",
    "        for offset in range(0, melspectra.shape[1]-steps_total, steps_total-steps_leadin):\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                #'height': _int64_feature(height),\n",
    "                #'width': _int64_feature(width),\n",
    "                #'image_raw': _bytes_feature(img_raw),\n",
    "                #'mask_raw': _bytes_feature(annotation_raw)\n",
    "                'mel': _floats_feature(melspectra[:, offset:offset+steps_total]),\n",
    "                'spectra_real': _floats_feature( spectra_complex[:, offset:offset+steps_total].imag ),\n",
    "                'spectra_imag': _floats_feature( spectra_complex[:, offset:offset+steps_total].imag ),\n",
    "            }))\n",
    "\n",
    "            w = writer_train  # Allocate these between the various train/validation/test files\n",
    "            if np.random.random()>0.8:\n",
    "                w = writer_valid\n",
    "                if np.random.random()>0.5:\n",
    "                    w = writer_test\n",
    "\n",
    "            w.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,]:\n",
    "    convert_wavs_to_spectra_learnable_records('./librivox/guidetomen_%02d_rowland_64kb.mp3' % (i,))\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
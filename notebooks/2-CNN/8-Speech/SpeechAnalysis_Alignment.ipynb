{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_step   = 12.5/1000. # 12.5ms\n",
    "fft_window = 50.0/1000.  # 50ms\n",
    "\n",
    "audio_filenames = [ './librivox/guidetomen_%02d_rowland_64kb.mp3' % (i,) for i in [1,2,3]]\n",
    "audio_filenames\n",
    "\n",
    "mel_filenames = [ f.replace('.mp3', '.melspectra.hkl') for f in audio_filenames ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filename_test_idx = 1 \n",
    "\n",
    "#Set #FILE: = #FILE:  guidetomen_02_rowland_64kb.mp3\n",
    "#Set #OFFSET_START: = #OFFSET_START: 7.0\n",
    "#Set #OFFSET_END: = #OFFSET_END: 613.0\n",
    "offset_start, offset_end = 7.0, 613.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_filename_test = mel_filenames[audio_filename_test_idx]\n",
    "\n",
    "#with open(mel_filename_test.replace('.hkl', '.16_k2.sym'), 'rt') as f:\n",
    "with open(mel_filename_test.replace('.hkl', '.64_k2.sym'), 'rt') as f:\n",
    "    mel_sym_str = f.read()\n",
    "    \n",
    "mel_sym_chars = set(mel_sym_str)\n",
    "mel_sym_dict  = { c:i for i,c in enumerate(sorted(list(mel_sym_chars))) }\n",
    "mel_sym = np.array( [mel_sym_dict[c] for c in mel_sym_str] )\n",
    "\n",
    "mel_sym_silence = mel_sym_dict[' ']\n",
    "\n",
    "mel_sym_str[100:115], mel_sym[100:115], mel_sym.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_one_sec_per_line(s, t_min=0., t_max=None):\n",
    "    #each_line = int(1/fft_step)\n",
    "    if t_max is None: t_max = len(s)*fft_step\n",
    "    for t in np.arange(t_min, t_max, 1.):\n",
    "        i_min = int(t/fft_step)\n",
    "        i_max = int((t+1.)/fft_step)\n",
    "        if i_max>t_max/fft_step: \n",
    "            i_max = int(t_max/fft_step)\n",
    "        print(\"%6.2f %s\" % (t, s[i_min:i_max]) )\n",
    "        \n",
    "print_one_sec_per_line(mel_sym_str, 0.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress the sym data, by counting the duplicates, \n",
    "# and storing 'initial char', 'char count' and 'initial char idx'\n",
    "mel_sym_ct, mel_sym_cc, mel_sym_cn = [], [], []\n",
    "prev_c, prev_n = '', 0\n",
    "for t, c in enumerate(mel_sym_str):\n",
    "    if c==prev_c: \n",
    "        prev_n+=1 # Add one to count\n",
    "    else:\n",
    "        mel_sym_cn.append(prev_n)  # Store count of previous char\n",
    "        mel_sym_ct.append(t)       # Start on new char's index\n",
    "        mel_sym_cc.append(c)       # Start on new char's value\n",
    "        prev_c, prev_n = c, 1\n",
    "mel_sym_cn.append(prev_n)  # Store last count value\n",
    "\n",
    "mel_sym_ct = np.array( mel_sym_ct )\n",
    "mel_sym_ci = np.array( [mel_sym_dict[c] for c in mel_sym_cc] )\n",
    "mel_sym_cn = np.array( mel_sym_cn[1:])   # Kill the first value, and convert to numpy\n",
    "\n",
    "(mel_sym_str[66:95],   # Original String \n",
    " mel_sym_cc[0:10],     # Distinct characters\n",
    " mel_sym_ci[0:10],     # Distinct symbol indicies\n",
    " mel_sym_cn[0:10],     #   x number of repetitions\n",
    " mel_sym_ct[0:10],     # mel time\n",
    " mel_sym_ci.shape[0],) # total number of mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the ranges of the actual sounds in the \n",
    "# speech audio - ignoring short silences\n",
    "\n",
    "#silence_is_short_len = 8  # 100ms\n",
    "silence_is_short_len = 40  # 500ms\n",
    "\n",
    "audio_spans = []\n",
    "def add_span(span_start_index, s_i, s_n):\n",
    "    if len(s_i)>0:\n",
    "        span=[]\n",
    "        for sym, count in zip(s_i, s_n):\n",
    "            span.extend( [sym]*count )\n",
    "        audio_spans.append(dict(\n",
    "            t_start=span_start_index,\n",
    "            t_end  =span_start_index+len(span),\n",
    "            syms=s_i,\n",
    "            count=s_n,\n",
    "            span=span,\n",
    "        ))\n",
    "        #print(span_start_index, \n",
    "        #      mel_sym_str[span_start_index:span_start_index+len(span)])\n",
    "\n",
    "span_start, span_i, span_n = -1, [], []  # Indices and counts\n",
    "for idx, c in enumerate(mel_sym_cc):\n",
    "    if span_start<0: \n",
    "        span_start = mel_sym_ct[idx]\n",
    "    ci, cn = mel_sym_ci[idx], mel_sym_cn[idx]\n",
    "    \n",
    "    if ci==mel_sym_silence and cn>silence_is_short_len:\n",
    "        #print(cn)\n",
    "        add_span(span_start, span_i, span_n)\n",
    "        span_start, span_i, span_n = -1, [], []\n",
    "        continue \n",
    "        \n",
    "    span_i.append(ci)\n",
    "    span_n.append(cn)\n",
    "add_span(span_start, span_i, span_n)\n",
    "\n",
    "len(audio_spans), #audio_spans[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take off the first few and last few (outside offset_start, offset_end)\n",
    "audio_spans = [a for a in audio_spans\n",
    "                  if  a['t_start']*fft_step>offset_start \n",
    "                  and a['t_end']  *fft_step<offset_end\n",
    "              ]\n",
    "len(audio_spans), #audio_spans[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random, string\n",
    "\n",
    "# pip install soundfile\n",
    "import soundfile\n",
    "import librosa\n",
    "\n",
    "from IPython.display import Audio as audio_playback_widget\n",
    "\n",
    "os.makedirs('./data/tmp', exist_ok=True)\n",
    "\n",
    "audio_filename_test = audio_filenames[audio_filename_test_idx]\n",
    "audio_samples, _sample_rate = librosa.core.load(audio_filename_test, sr=None)\n",
    "audio_samples = audio_samples/np.max(audio_samples)\n",
    "\n",
    "def play_audio_span(s, autoplay=False):\n",
    "    hsh = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
    "    f = './data/tmp/%s.wav' % (hsh,)\n",
    "    def ts(t_mel, end=False):  # t_mel to samples\n",
    "        return int( (t_mel*fft_step + (fft_window if end else 0.))*_sample_rate )\n",
    "    audio_span = audio_samples[ts(s['t_start']):ts(s['t_end'], end=True)]\n",
    "    soundfile.write(f, audio_span, samplerate=_sample_rate)\n",
    "    \n",
    "    plt.figure(figsize=(12,2))\n",
    "    plt.plot(audio_span)\n",
    "    #plt.plot(np.arange(s['t_start'],s['t_end'],), audio_span)\n",
    "    #plt.xticks( np.arange(s['t_start'], s['t_end'], 20.), rotation=90 )\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return audio_playback_widget(f, autoplay=autoplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_audio_span(audio_spans[0])  # audio_span[0] is first word in text\n",
    "#play_audio_span(audio_spans[113])  # audio_span[-1] is last phrase in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelors  (near beginning)\n",
    "print_one_sec_per_line(mel_sym_str, 0./80, 800./80)\n",
    "#play_audio_span(dict(t_start=0, t_end=800), autoplay=True)\n",
    "print()\n",
    "print_one_sec_per_line(mel_sym_str, 640./80, 700./80)\n",
    "play_audio_span(dict(t_start=640, t_end=690), autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in text as words\n",
    "\n",
    "# Create initial array of word starts\n",
    "#   with initial guess of maximum error bars\n",
    "# Create map of word -> word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mel_filename_test.replace('.melspectra.hkl', '.txt'), 'rt') as f:\n",
    "    mel_txt = f.read()\n",
    "\n",
    "txt_arr = mel_txt.replace('\\n', ' ').split(' ')\n",
    "#txt_arr.insert(0, '#EOS') # Extra one at start\n",
    "#txt_arr.insert(0, '') # Helps start process \n",
    "len(txt_arr), ','.join( txt_arr[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick-and-dirty sanity check : Flip all words over and expect failure\n",
    "#txt_arr = txt_arr[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_spans = []\n",
    "def add_sentence_span(span_start_index, span):\n",
    "    if len(span)>0:\n",
    "        sentence_spans.append(dict(\n",
    "            t_start= span_start_index, # within txt_arr\n",
    "            t_end  = span_start_index+len(span),\n",
    "            span   = span,\n",
    "        ))\n",
    "\n",
    "span_start, span_words = -1, []  # Indices and text\n",
    "for idx, w in enumerate(txt_arr):\n",
    "    if span_start<0: \n",
    "        span_start = idx\n",
    "    if w=='#EOS':\n",
    "        add_sentence_span(span_start, span_words)\n",
    "        span_start, span_words = -1, []\n",
    "        continue \n",
    "    span_words.append(w)\n",
    "add_sentence_span(span_start, span_words)\n",
    "\n",
    "len(sentence_spans), sentence_spans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some matrices to fill in - these are timings in seconds \n",
    "txt_length_est = np.array( [ len(s.replace('#EOS', '#EOS-is-longish')) for s in txt_arr ] )\n",
    "#txt_err = np.zeros_like( txt_starts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total up the lengths of the words (in characters) \n",
    "#  - the initial timing guess is going to be proportional \n",
    "txt_length_est[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_err_min = 1. # Seconds\n",
    "txt_err_pct = 0.10 # i.e. plus or minus this amount of 'unknown length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need function to fix starts and errs for every word in txt_arr\n",
    "#   given a dict of word_index to known starts+errs\n",
    "known_starts = {\n",
    "    #0 : (offset_start, txt_err_min),\n",
    "    #(txt_length_est.shape[0]-1) : (offset_end, txt_err_min),\n",
    "    0 : (audio_spans[0]['t_start']*fft_step, txt_err_min),\n",
    "    (txt_length_est.shape[0]-1) : (audio_spans[-1]['t_end']*fft_step, txt_err_min),\n",
    "}\n",
    "known_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_starts_and_errs(known_starts):\n",
    "    txt_starts  = np.zeros( txt_length_est.shape )\n",
    "    txt_err_fwd = np.zeros_like( txt_starts )\n",
    "    txt_err_bwd = np.zeros_like( txt_starts )\n",
    "    \n",
    "    known_start_i = sorted( known_starts.keys() )\n",
    "    for i_start, i_end in  zip( known_start_i[:-1], known_start_i[1:]):\n",
    "        v_start, v_end = known_starts[i_start], known_starts[i_end]\n",
    "        \n",
    "        # Create a span including updated duration estimates\n",
    "        actual_duration = (v_end[0]-v_start[0])\n",
    "        length_est = txt_length_est[i_start:i_end] # Copy range\n",
    "        length_adj = length_est/length_est.sum()*actual_duration\n",
    "        \n",
    "        # Put the span into the txt_starts array\n",
    "        cs_fwd = np.cumsum(length_adj)\n",
    "        cs_bwd = np.flip(np.flip(length_adj, 0).cumsum(), 0)\n",
    "        \n",
    "        txt_starts[i_start] = v_start[0]\n",
    "        txt_starts[i_start+1:i_end+1] = v_start[0] + cs_fwd\n",
    "\n",
    "        txt_err_fwd[i_start] = v_start[1]\n",
    "        txt_err_fwd[i_start+1:i_end+1] = v_start[1] + cs_fwd*txt_err_pct\n",
    "\n",
    "        txt_err_bwd[i_end] = v_end[1]\n",
    "        txt_err_bwd[i_start:i_end] = v_end[1] + cs_bwd*txt_err_pct\n",
    "    \n",
    "    return txt_starts, np.minimum(txt_err_fwd, txt_err_bwd)\n",
    "\n",
    "#np.cumsum( np.array( [66,3,72,12,42] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_starts, txt_err = create_starts_and_errs(known_starts)\n",
    "\n",
    "txt_length_est[0:10], txt_starts[0:10], txt_starts[-10:]\n",
    "txt_err[0:5], txt_err[ txt_starts.shape[0]//2-5:txt_starts.shape[0]//2 ], txt_err[-5:], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(txt_starts, 'b')\n",
    "plt.plot(txt_err*8., 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old version\n",
    "#txt_starts = txt_length_est.cumsum()\n",
    "#txt_starts = offset_start + txt_starts*(offset_end-offset_start)/txt_starts[-1]\n",
    "#txt_starts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old version\n",
    "#txt_err = np.array( [ (i-txt_starts.shape[0]) for i, txt in enumerate(txt_arr) ] )\n",
    "#txt_err = np.square(txt_err)\n",
    "#txt_err = txt_err.max() - txt_err # Now a parabola peaking in the middle\n",
    "#\n",
    "#txt_err_scale = (txt_err_max - txt_err_min) / txt_err[ txt_starts.shape[0]//2 ]\n",
    "#\n",
    "#txt_err = txt_err*txt_err_scale + txt_err_min\n",
    "#\n",
    "#txt_err[0:5], txt_err[ txt_starts.shape[0]//2:txt_starts.shape[0]//2+5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global alignment\n",
    "\n",
    "# Idea : Train up a word embedding based on range (within error bars)\n",
    "# Function to map word to set of ranges\n",
    "# Function to convert ranges into a % of whole\n",
    "# Table of words with % coverage (to check whether that's a doable idea)\n",
    "# Find word-range average vector (vs. not-in-word-range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx={}\n",
    "for i, w in enumerate(txt_arr):\n",
    "    if w not in word_to_idx: word_to_idx[w]=[]\n",
    "    word_to_idx[w].append( i )\n",
    "word_to_idx['bachelors'], len(txt_arr), len(word_to_idx)  #bachelor mere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_range_mask(w):\n",
    "    mask = np.zeros_like(mel_sym)\n",
    "    for i in word_to_idx.get(w, []):\n",
    "        t_min = (txt_starts[i]-txt_err[i])\n",
    "        if t_min<0: t_min=0\n",
    "        \n",
    "        if i+1 < txt_starts.shape[0]:\n",
    "            i_next = i+1\n",
    "        else: # Rare end-case:\n",
    "            i_next = i\n",
    "        t_max = txt_starts[i_next]+txt_err[i]\n",
    "            \n",
    "        #print(\"(i_min, i_max) = \", i_min, i_max)\n",
    "        mask[ int(t_min/fft_step):int(t_max/fft_step) ] = 1.\n",
    "    return mask\n",
    "\n",
    "word_mask=word_range_mask('bachelors')  # bachelor mere woman man the\n",
    "np.sum(word_mask) / word_mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(word_mask, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at word frequencies, and mask coverage\n",
    "words_freq_ordered = sorted(word_to_idx.keys(), key=lambda k: -len(word_to_idx[k]))\n",
    "len(words_freq_ordered), words_freq_ordered[0], words_freq_ordered[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words_freq_ordered:\n",
    "    n = len(word_to_idx[w])\n",
    "    if n<2: continue # Not enough for any meaningful stats...\n",
    "    word_mask=word_range_mask(w)\n",
    "    coverage=np.sum(word_mask) / word_mask.shape[0]\n",
    "    print(\"%6.2f%%, %4d, %s\" % (coverage*100., n, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweet spot is defined by maximising # of examples, while minimising\n",
    "#   probability of mis-identification (i.e. low coverage is good)\n",
    "# Perhaps, though, need to avoid overlapping masks (if possible?)\n",
    "\n",
    "# Candidates (?) : love, one, never, how, marriage, give, me, right, greatest, getting\n",
    "# Except : bachelor's and bachelors, \n",
    "# Except : man(~woman), woman's, man's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_sym_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create histogram of symbol frequencies corresponding to mask\n",
    "def histogram_freqs(mask, remove_silence=True):\n",
    "    print(np.sum(mask) / mask.shape[0])\n",
    "    #inside = bincount(mel_sym, weights=mask)\n",
    "    n_sym = len(mel_sym_chars)\n",
    "    \n",
    "    inside_bins  = np.bincount(mel_sym, weights=mask)\n",
    "    outside_bins = np.bincount(mel_sym, weights=1-mask)\n",
    "    \n",
    "    if remove_silence:\n",
    "        inside_bins[mel_sym_silence]=0\n",
    "        outside_bins[mel_sym_silence]=0\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    rects1 = plt.bar(np.arange(0, n_sym)-.2, width=0.4, color='r',\n",
    "                     height=inside_bins/np.sum(inside_bins))\n",
    "    rects2 = plt.bar(np.arange(0, n_sym)+.2, width=0.4, color='b',\n",
    "                     height=outside_bins/np.sum(outside_bins))\n",
    "\n",
    "    plt.xlabel('Symbol#')\n",
    "    plt.ylabel('Freq')\n",
    "    plt.xticks(np.arange(0, n_sym, 1.0))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "histogram_freqs(word_range_mask('bachelors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local alignment (looking within word-error-bar ranges only)\n",
    "\n",
    "# Idea : Mostly textual alignment\n",
    "# Have a look symbols in appropriate ranges for several word examples\n",
    "# See whether a simple optimisation can align multiple segments\n",
    "# Would reduce error bars massively\n",
    "# Possibly : \n",
    "#   http://mlpy.sourceforge.net/docs/3.4/lcs.html#standard-lcs  (GPL3, though)\n",
    "#   https://github.com/Samnsparky/py_common_subseq (MIT)\n",
    "#   https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Longest_common_substring#Python_3 \n",
    "#   https://docs.python.org/3/library/difflib.html (not quite...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !pip install py_common_subseq\n",
    "#import py_common_subseq as subseq  # But doesn't output alignment\n",
    "\n",
    "# Homebrew version : does what we actually want (return array of index correspondences)\n",
    "#  See : https://en.wikipedia.org/wiki/Longest_common_subsequence_problem\n",
    "def lcs(a_arr, b_arr, just_length=True):  \n",
    "    m = np.zeros( (len(a_arr)+1, len(b_arr)+1) )\n",
    "    # offset all the i and j by 1, since we need blank first row+col\n",
    "    for i, a in enumerate(a_arr):\n",
    "        for j, b in enumerate(b_arr):\n",
    "            if a == b:\n",
    "                m[i+1, j+1] = m[i, j] + 1\n",
    "            else:\n",
    "                m[i+1, j+1] = max(m[i+1, j], m[i, j+1])\n",
    "    #print(m)\n",
    "    if just_length:\n",
    "        return m[-1, -1]\n",
    "                \n",
    "    #?  a_i=np.zeros( (lengths[-1,-1], ))\n",
    "    a_i, b_i = [], []\n",
    "    i, j = len(a_arr), len(b_arr)\n",
    "    while i>0 and j>0:\n",
    "        if m[i, j] == m[i-1, j]:\n",
    "            i -= 1\n",
    "        elif m[i, j] == m[i, j-1]:\n",
    "            j -= 1\n",
    "        else: # a_arr[i-1] == b_arr[j-1]\n",
    "            a_i.append(i-1)\n",
    "            b_i.append(j-1)\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    \n",
    "    return a_i[::-1], b_i[::-1]\n",
    "\n",
    "lcs([17, 9,99,7,4,8,3,7,5,2,4,1,2,1,2,4,5,6],\n",
    "    [1, 17,11,7,4,8,3,7,0,2,4,0,2,  2,  5,6], just_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now let's pick a word, and find its shortest range\n",
    "# Then go through 1 second (=80 position) chunks within that range,\n",
    "# and see how that matches each of the ~1000 spans \n",
    "# (possibly by searching over overlapping 2 second chunks) \n",
    "\n",
    "#word_probe = 'greatest'\n",
    "#word_probe = 'getting'\n",
    "word_probe = 'bachelors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the audio_spans that overlap the mask for this word\n",
    "mask_probe = word_range_mask(word_probe)\n",
    "spans_probe = [ s for s in audio_spans \n",
    "                if mask_probe[s['t_start']]>0 \n",
    "                or mask_probe[s['t_end']-1]>0 ]\n",
    "len(spans_probe), len(audio_spans), np.sum(mask_probe)/mask_probe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now go through these spans in segments of 1 second, in 0.5 second increments...\n",
    "probe_win = int(1./fft_step)\n",
    "probe_step = probe_win//2\n",
    "\n",
    "probe_results=None\n",
    "def get_probe_results(spans_probe):\n",
    "    probe_res=[]  # Will be a list of probe score arrays\n",
    "    for sp in spans_probe:\n",
    "        #for i in range(sp['t_start'], sp['t_end'], probe_step):\n",
    "        for i in range(0, len(sp['span']), probe_step):\n",
    "            segment_probe = sp['span'][i:i+probe_win]\n",
    "            #print( i, sp['span'] )\n",
    "            #print( segment_probe )\n",
    "            #break\n",
    "            # And scan the segment_probe across all the spans in the audio,\n",
    "            #   With similar windowing idea\n",
    "\n",
    "            audio_res = []\n",
    "            for sa in audio_spans:\n",
    "                #for j in range(sa['t_start'], sa['t_end'], probe_step):\n",
    "                for j in range(0, len(sa['span']), probe_step):\n",
    "                    segment_audio = sa['span'][j:j+probe_win]\n",
    "\n",
    "                    probe_minlen = min(len(segment_probe), len(segment_audio))\n",
    "                    audio_res.append( lcs(segment_audio, segment_probe)/(probe_minlen+1) )\n",
    "\n",
    "            probe_res.append( audio_res )\n",
    "        #break\n",
    "\n",
    "    return np.array( probe_res )\n",
    "\n",
    "# Don't do this unless you intend to...\n",
    "#probe_results = get_probe_results(spans_probe)\n",
    "#probe_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[5,6,7,6,8][2:13]\n",
    "if probe_results is not None:\n",
    "    probe_results.sum() \n",
    "    \n",
    "    plt.figure(figsize = (20,2))\n",
    "    plt.imshow(probe_results, cmap='Purples')  #, interpolation='nearest'\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding for all the symbols\n",
    "sym_embed = np.random.normal( size=(len(mel_sym_chars), embedding_dim) )\n",
    "sym_embed = sym_embed / np.linalg.norm(sym_embed, axis=1)[:, np.newaxis]\n",
    "sym_embed[mel_sym_silence, :] = 0.\n",
    "\n",
    "sym_embed[3,:], np.linalg.norm(sym_embed[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined embedding for each audio_span\n",
    "\n",
    "#        audio_spans.append(dict(\n",
    "#            t_start=span_start_index,\n",
    "#            t_end  =span_start_index+len(span),\n",
    "#            syms=s_i,\n",
    "#            count=s_n,\n",
    "#            span=span,\n",
    "#        ))\n",
    "\n",
    "overall_bins= np.bincount(mel_sym)\n",
    "overall_emb = np.dot(overall_bins, sym_embed)\n",
    "overall_emb /= np.linalg.norm(overall_emb)\n",
    "\n",
    "audio_spans_embedding = np.zeros( (len(audio_spans), embedding_dim))\n",
    "for i, s in enumerate(audio_spans):\n",
    "    #np.bincount( np.array([1,2,6,5,3,3,2,5,1,1,0,1]), minlength=10)\n",
    "    #print(i, mel_sym[ s['t_start']:s['t_end']] )\n",
    "    inside_bins = np.bincount(mel_sym[ s['t_start']:s['t_end'] ], \n",
    "                            minlength=len(mel_sym_chars))\n",
    "\n",
    "    inside_emb  = np.dot( inside_bins, sym_embed)\n",
    "    inside_emb /= np.linalg.norm(inside_emb)\n",
    "\n",
    "    #outside_emb = overall_emb - inside_emb\n",
    "    span_emb = inside_emb - overall_emb\n",
    "\n",
    "    norm = np.linalg.norm(span_emb)\n",
    "    if norm>0.:\n",
    "        span_emb /= norm\n",
    "\n",
    "    #print(i, span_emb)\n",
    "    audio_spans_embedding[i,:] = span_emb\n",
    "\n",
    "#overall_emb\n",
    "print(audio_spans_embedding[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.dot(audio_spans_embedding, audio_spans_embedding.T), \n",
    "           aspect='auto', origin='lower', interpolation='nearest', \n",
    "           vmin=-1., vmax=1., cmap='bwr')\n",
    "plt.grid(True)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every word (n_occurrences>0) create embedding via masks\n",
    "#   NB: masks depend on current txt_starts, txt_err\n",
    "\n",
    "def create_word_embeddings():\n",
    "    word_embed = dict()\n",
    "    \n",
    "    overall_bins= np.bincount(mel_sym)\n",
    "    overall_emb = np.dot(overall_bins, sym_embed)\n",
    "    overall_emb /= np.linalg.norm(overall_emb)\n",
    "    \n",
    "    #for w in words_freq_ordered:\n",
    "    for w in word_to_idx.keys():\n",
    "        n = len(word_to_idx[w])\n",
    "        if n<2: \n",
    "            # Not enough for any logic operations to make a difference...\n",
    "            continue \n",
    "            \n",
    "        word_mask=word_range_mask(w)\n",
    "        if np.sum(word_mask) > 0.80*word_mask.shape[0]:\n",
    "            # Too broad to be worthwhile... (includes #EOS)\n",
    "            continue \n",
    "        \n",
    "        inside_bins = np.bincount(mel_sym, weights=word_mask)\n",
    "        inside_emb  = np.dot( inside_bins, sym_embed)\n",
    "        inside_emb /= np.linalg.norm(inside_emb)\n",
    "\n",
    "        #outside_emb = overall_emb - inside_emb\n",
    "        #word_emb = inside_emb - outside_emb\n",
    "        \n",
    "        word_emb = inside_emb - overall_emb\n",
    "\n",
    "        norm = np.linalg.norm(word_emb)\n",
    "        if norm>0.:\n",
    "            word_emb /= norm\n",
    "        #else == nonsense\n",
    "\n",
    "        word_embed[w]=word_emb\n",
    "    return word_embed\n",
    "\n",
    "word_embedding = create_word_embeddings()\n",
    "#len(word_embedding)\n",
    "word_embedding['love'], word_embedding['bachelors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined embedding for each sentence\n",
    "#   Uses the word_embeddings above (will change if txt_starts, txt_err changes)\n",
    "#txt_arr[:6], txt_arr[-6:]\n",
    "\n",
    "#        sentence_spans.append(dict(\n",
    "#            t_start= span_start_index,\n",
    "#            t_end  = span_start_index+len(span),\n",
    "#            span   = span,\n",
    "#        ))\n",
    "\n",
    "def create_sentence_embedding(word_embedding):\n",
    "    ss_embedding = np.zeros( (len(sentence_spans), embedding_dim))\n",
    "    for i, s in enumerate(sentence_spans):\n",
    "        span_emb = np.zeros( (embedding_dim,) )\n",
    "        for w in s['span']:\n",
    "            if w in word_embedding:\n",
    "                span_emb += word_embedding[w]\n",
    "        norm = np.linalg.norm(span_emb)\n",
    "        if norm>0.:\n",
    "            span_emb /= norm\n",
    "        else:\n",
    "            span_emb = word_embedding['marriage']  # Aribitrary to avoid ==0\n",
    "        ss_embedding[i, :] = span_emb\n",
    "    return ss_embedding\n",
    "\n",
    "sentence_spans_embedding = create_sentence_embedding(word_embedding)        \n",
    "\n",
    "print(sentence_spans[0]['span'])\n",
    "print(sentence_spans_embedding[0])\n",
    "print(sentence_spans_embedding[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.dot(sentence_spans_embedding, sentence_spans_embedding.T), \n",
    "           aspect='auto', origin='lower', interpolation='nearest', \n",
    "           vmin=-1., vmax=1., cmap='bwr')\n",
    "plt.show()  # Sentences are much more dissimilar if rare words are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_spans_embedding.shape, audio_spans_embedding.shape\n",
    "#((69, 8), (114, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a vector DTW across spans and sentences\n",
    " \n",
    "cost_matrix, warp_path = librosa.dtw(\n",
    "    audio_spans_embedding.T, sentence_spans_embedding.T, \n",
    "    metric='cosine', subseq=False,\n",
    "    #step_sizes_sigma = np.array([[1, 1], [0, 1], [1, 0]]),\n",
    "    #weights_add = np.array([0, 0, 0]),\n",
    "    #weights_mul = np.array([1, 1, 1]),\n",
    "    \n",
    "    step_sizes_sigma = np.array([[1, 1], [1, 0]]),  # Disallow 2 sentences for 1 audio\n",
    "    weights_add = np.array([0, 0]),\n",
    "    weights_mul = np.array([1, 1]),\n",
    "    \n",
    "    #band_rad=0.25\n",
    ")\n",
    "cost_matrix.shape, warp_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Graph out the DTW path\n",
    "#     See : https://musicinformationretrieval.com/dtw_example.html\n",
    "plt.imshow(cost_matrix.T, aspect='auto', origin='lower', \n",
    "           interpolation='nearest', cmap='gray')\n",
    "plt.plot(warp_path[:,0], warp_path[:,1], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=29; sentence_spans_embedding[i,:], ' '.join(sentence_spans[i]['span'])\n",
    "#warp_path  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to output sentence and audio in that span\n",
    "warp_path[ warp_path[:,1]==i, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 == 'a fool and her money are soon courted'\n",
    "play_audio_span(audio_spans[48])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Output new 'known_starts' dictionary\n",
    "#   Update txt_starts, txt_err\n",
    "def add_copy_path_to_known_starts(warp_path, txt_err_min_new=txt_err_min*2.0):\n",
    "    #known_starts = dict()\n",
    "    #new_starts = {\n",
    "    #    0 : (offset_start, txt_err_min_new),\n",
    "    #    (txt_length_est.shape[0]-1) : (offset_end, txt_err_min_new),\n",
    "    #}\n",
    "    new_starts = dict( known_starts )\n",
    "\n",
    "    #audio_spans    warp_path[:,0] t_start= span_start_index, # within mel_arr\n",
    "    #sentence_spans warp_path[:,1] t_start= span_start_index, # within txt_arr\n",
    "    \n",
    "    # There are more audio_spans than sentence_spans\n",
    "    # So, for each sentence, look for the series of audios that correspond\n",
    "    # and pick the ?middle? one as the anchor\n",
    "    for i, s in enumerate(sentence_spans):\n",
    "        audio_span_i_arr = warp_path[ warp_path[:,1]==i, 0]\n",
    "        #print(audio_span_i_arr)\n",
    "        #audio_span_i = audio_span_i_arr[ audio_span_i_arr.shape[0]//2 ]\n",
    "        audio_span_i = audio_span_i_arr[ -1 ]\n",
    "        #print(audio_span_i)\n",
    "\n",
    "        start_sec = audio_spans[audio_span_i]['t_start']*fft_step\n",
    "        if start_sec<offset_start:\n",
    "            start_sec=offset_start\n",
    "        \n",
    "        new_starts[ s['t_start'] ] = ( start_sec, txt_err_min_new )\n",
    "        #print(\"%6d -> (%6.2f, %6.2f)\" % (s['t_start'], start_sec, txt_err_min_new,))\n",
    "    \n",
    "    txt_starts, txt_err = create_starts_and_errs(new_starts)\n",
    "    \n",
    "    return txt_starts, txt_err\n",
    "    \n",
    "txt_starts, txt_err = add_copy_path_to_known_starts(warp_path, 3.0)\n",
    "#known_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding['love'], word_embedding['bachelors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = create_word_embeddings()\n",
    "sentence_spans_embedding = create_sentence_embedding(word_embedding)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding['love'], word_embedding['bachelors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://colinraffel.com/publications/thesis.pdf\n",
    "\n",
    "# Idea : Align symbols using linear DTW (v fast)\n",
    "# Assign random increments to symbols, and see whether linear DTW can match the alignments\n",
    "# https://blog.acolyer.org/2016/05/11/searching-and-mining-trillions-of-time-series-subsequences-under-dynamic-time-warping/\n",
    "\n",
    "# Idea : Align (using DTW) the mels or embeddings within the word-error-bar segments\n",
    "# This would be multiple small alignments too\n",
    "# Needs vector DTW (like librosa has...)\n",
    "\n",
    "#  https://github.com/pierre-rouanet/dtw (GPL3 : Unusable)\n",
    "#  https://github.com/slaypni/fastdtw/tree/master/fastdtw  (MIT)\n",
    "#  https://github.com/ricardodeazambuja/DTW (cardiod example : CC0 licensed)\n",
    "\n",
    "\n",
    "## Combo\n",
    "\n",
    "# Use global word embeddings to weight samples in local ranges\n",
    "\n",
    "\n",
    "## Global alignment\n",
    "\n",
    "# Idea : Train up a word embedding based on range (within error bars)\n",
    "# Find word-range average vector (vs. not-in-word-range)\n",
    "# Use this to do a DTW across all words vs all timesteps\n",
    "\n",
    "# Alternative : Use same word embedding to do some kind of annealing :\n",
    "#   gradually reducing error bars (and improving embedding, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_spans), len(sentence_spans)\n",
    "#sentence_spans[32]['t_start'], txt_starts[707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the sentence timings\n",
    "txt_starts, txt_err = create_starts_and_errs(known_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-DTW approach : First guess is to chose nearest-neighbours \n",
    "#  between sentence_spans position guesses and audio_spans\n",
    "#  BUT : What if the nearest neighbours create dupes?  \n",
    "#     Could use some kind of repulsion (like a chain of springs)...  \n",
    "#     Or: First come, first served, others 'free' (or both 'free')\n",
    "\n",
    "\n",
    "# Go through the sentence_spans, and walk a pointer in the audio_spans\n",
    "#   beyond the estimated start.  Then choose the closest of the \n",
    "#   audio_spans starts (previous one or this one)\n",
    "#   If previous one chosen, check whether it is already 'occupied' - \n",
    "#     and in that case 'free' both this and the previous sentence...\n",
    "def sentence_ends_find_nearest_audio_gaps():\n",
    "    s_to_a = [None]*len(sentence_spans)\n",
    "\n",
    "    a_i = 1 # Start ahead of the beginning (eliminate one end-case)\n",
    "    for i, s in enumerate(sentence_spans):\n",
    "        s_t = txt_starts[ s['t_start'] ]/fft_step\n",
    "        while (a_i<len(audio_spans) and audio_spans[a_i]['t_start']<s_t):\n",
    "            #print(a_i, s_t)\n",
    "            a_i += 1\n",
    "        if a_i>=len(audio_spans):\n",
    "            if s_to_a[i-1] is None:\n",
    "                s_to_a[i] = a_i-1  # Assigns the last one if unclaimed\n",
    "            break\n",
    "        # Find which is closer\n",
    "        d_this = np.abs(s_t - audio_spans[a_i  ]['t_start'])\n",
    "        d_prev = np.abs(s_t - audio_spans[a_i-1]['t_start'])\n",
    "        if d_this<d_prev:\n",
    "            s_to_a[i] = a_i\n",
    "        else:\n",
    "            if i==0 or s_to_a[i-1] != a_i-1:\n",
    "                s_to_a[i] = a_i-1\n",
    "            else:\n",
    "                s_to_a[i-1] = None # Free both\n",
    "    return s_to_a\n",
    "\n",
    "s_to_a = sentence_ends_find_nearest_audio_gaps()\n",
    "for a in s_to_a: print(a,', ', end=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the values in s_to_a to create a new mapping\n",
    "def s_to_a_to_starts(s_to_a, txt_err_min_new = 5.):\n",
    "    #new_starts = {\n",
    "    #    0 : (offset_start, txt_err_min),\n",
    "    #    (txt_length_est.shape[0]-1) : (offset_end, txt_err_min),\n",
    "    #}\n",
    "    #print(new_starts)\n",
    "    new_starts = dict( known_starts )\n",
    "    \n",
    "    for s_i, a_i in enumerate(s_to_a):\n",
    "        if a_i is None:\n",
    "            continue\n",
    "        s = sentence_spans[s_i]\n",
    "        \n",
    "        start_sec = audio_spans[ a_i ]['t_start']*fft_step\n",
    "        if start_sec<offset_start:\n",
    "            start_sec=offset_start\n",
    "\n",
    "        new_starts[ s['t_start'] ] = ( start_sec, txt_err_min_new )\n",
    "        #print(\"%6d -> (%6.2f, %6.2f)\" % (s['t_start'], start_sec, txt_err_min_new,))\n",
    "    return new_starts\n",
    "\n",
    "# Actually, leave this to one side for a bit...\n",
    "#txt_starts, txt_err = s_to_a_to_starts(s_to_a)\n",
    "#s_to_a_to_starts(s_to_a)\n",
    "\n",
    "txt_starts, txt_err_ignore = create_starts_and_errs( s_to_a_to_starts(s_to_a) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(txt_starts, 'b')\n",
    "plt.plot(txt_err*10., 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = create_word_embeddings()\n",
    "sentence_spans_embedding = create_sentence_embedding(word_embedding)    \n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.dot(sentence_spans_embedding, sentence_spans_embedding.T), \n",
    "           aspect='auto', origin='lower', interpolation='nearest', \n",
    "           vmin=-1., vmax=1., cmap='bwr')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List neighbouring sentences that have the lowest dot products\n",
    "def get_sorted_sentence_span_contrasts():\n",
    "    sentence_span_contrast=[]\n",
    "    for i in range(0, len(sentence_spans)-2):  \n",
    "        sentence_span_contrast.append( (\n",
    "            np.dot(sentence_spans_embedding[i,:], sentence_spans_embedding[i+1,:]),\n",
    "            i, i+1)\n",
    "        )\n",
    "    return sorted(sentence_span_contrast)\n",
    "\n",
    "get_sorted_sentence_span_contrasts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=42\n",
    "print( sentence_spans_embedding[i,:])\n",
    "print( sentence_spans_embedding[i+1,:])\n",
    "print( np.dot(sentence_spans_embedding[i,:], sentence_spans_embedding[i+1,:]) )\n",
    "print(str(i)  +') '+' '.join(sentence_spans[i]['span']) )\n",
    "print(str(i+1)+') '+' '.join(sentence_spans[i+1]['span']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through audio_spans within 'striking range' of a given sentence start\n",
    "#  And find the dot product with that sentence\n",
    "\n",
    "def return_sentence_vs_audio_dots(i):\n",
    "    #print(sentence_spans[i])\n",
    "    t_start = sentence_spans[i]['t_start']\n",
    "    t_end   = sentence_spans[i]['t_end']\n",
    "    if t_end+1 < len(txt_starts):\n",
    "        t_end += 1\n",
    "    \n",
    "    #print( txt_starts[ t_start ], txt_err[ t_start ] )\n",
    "    #print( txt_starts[ t_end ], txt_err[ t_end ] )\n",
    "    \n",
    "    t_min = (txt_starts[ t_start ] - txt_err[ t_start ])/fft_step\n",
    "    t_max = (txt_starts[ t_end ]   + txt_err[ t_end ]  )/fft_step\n",
    "    #print(t_min, t_max)\n",
    "    \n",
    "    a_arr, dots = [],[]\n",
    "    for a_i, a in enumerate(audio_spans):\n",
    "        if a['t_start']>t_max or a['t_end']<t_min:\n",
    "            continue\n",
    "        a_arr.append(a_i)\n",
    "        dots.append(np.dot(sentence_spans_embedding[i,:], \n",
    "                           audio_spans_embedding[a_i, :] ))\n",
    "    #print(dots)\n",
    "    return a_arr, dots\n",
    "\n",
    "# i set in previous cell : 'contrasting adjacent sentences'\n",
    "x,y = return_sentence_vs_audio_dots(i)\n",
    "plt.plot(x,y, 'b-*')\n",
    "\n",
    "x,y = return_sentence_vs_audio_dots(i+1)\n",
    "plt.plot(x,y, 'r-*')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title(\"Looking for blue decline with simultaneous red increase\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=64\n",
    "#print( audio_spans[j]['t_start'], audio_spans[j]['t_end'], )\n",
    "play_audio_span(audio_spans[j], autoplay=True)  \n",
    "#play_audio_span(audio_spans[j+1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what?  We have an alignment that could let us train the words \n",
    "#   (either better, or for the first time)\n",
    "# Assume we train the words now (and get sentence embeddings)\n",
    "#   Could we do some kind of nudging into the right alignment?\n",
    "\n",
    "#   Looking at behaviour of sentence-sentence embedding cosines above\n",
    "#   it seems like things are initially very vague, but later form \n",
    "#   stronger (mainly negative) opinions where the alignment is wrong\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flickr30k Captions to Corpus\n",
    "\n",
    "*   P. Young, A. Lai, M. Hodosh, and J. Hockenmaier. _From image description to visual denotations: New similarity metrics for semantic inference over event descriptions._ Transactions of the Association for Computational Linguistics (to appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "t_start=datetime.datetime.now()\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './data/Flickr30k'\n",
    "#image_path = os.path.join(data_path, 'flickr30k-images')\n",
    "cache_dir = os.path.join(data_path, '../cache/Flickr30k')\n",
    "\n",
    "#BATCHSIZE=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plan \n",
    "\n",
    "*  Have a look inside the captions ```flickr30k.tar.gz``` : includes ```results_20130124.token```\n",
    "*  Extract contents of ```flickr30k.tar.gz``` to ```dict( photo_id -> [captions] )```\n",
    "*  Filter out a subset of those ```photo_id``` to convert\n",
    "*  Save off image array and corpus to an easy-to-load filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_to_captions=dict()\n",
    "\n",
    "tarfilepath = os.path.join(data_path, 'flickr30k.tar.gz')\n",
    "if os.path.isfile(tarfilepath):\n",
    "    import tarfile\n",
    "    with tarfile.open(tarfilepath, 'r:gz').extractfile('results_20130124.token') as tokenized:\n",
    "        n_captions = 0\n",
    "        for l in tokenized.readlines():\n",
    "            #print(l)  # This is bytes\n",
    "            img_num, caption = l.decode(\"utf-8\").strip().split(\"\\t\")\n",
    "            img, num = img_num.split(\"#\")\n",
    "            #print(img, caption); break\n",
    "            if img not in img_to_captions:  img_to_captions[img]=[]\n",
    "            img_to_captions[img].append(caption)\n",
    "            n_captions += 1\n",
    "            \n",
    "print(\"Found %d images, with a total of %d captions\" % (len(img_to_captions),n_captions, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_img_to_captions, good_img_to_captions_title = img_to_captions, 'all'\n",
    "len(good_img_to_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter for the images that we care about\n",
    "import re\n",
    "good_caption = re.compile( r'\\b(cat|kitten)s?\\b', flags=re.IGNORECASE )\n",
    "good_img_to_captions = { img:captions\n",
    "                            for img, captions in img_to_captions.items() \n",
    "                            for caption in captions \n",
    "                            if good_caption.search( caption )\n",
    "                       }  # img=='3947306345.jpg'\n",
    "good_img_to_captions_title = 'feline'\n",
    "#good_img_to_captions\n",
    "len(good_img_to_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_arr = sorted(good_img_to_captions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the vocab\n",
    "word_freq=dict()\n",
    "\n",
    "for img in img_arr:\n",
    "#for img in img_to_captions.keys():\n",
    "    for caption in img_to_captions[img]:\n",
    "        for w in caption.lower().split():\n",
    "            if not w in word_freq: word_freq[w]=0\n",
    "            word_freq[w] += 1\n",
    "#word_freq\n",
    "freq_word = sorted([ (f,w) for w,f in word_freq.items() if f>0], reverse=True)\n",
    "len(freq_word), freq_word[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[ (w,f) for w,f in word_freq.items() if not w.isalpha() and '-' not in w and f>0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set ( stopwords.words('english') )\n",
    "punc = set (\"- . , : ; ' \\\" & $ % ( ) ! ?\".split())\n",
    "\n",
    "[ (w, w in stop_words) for w in \"while with of at in\".split() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words_seen = set( word_freq.keys() ).intersection( stop_words.union(punc) )\n",
    "\n",
    "', '.join(stop_words_seen)\n",
    "len(stop_words_seen), len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the data into a useful structure\n",
    "\n",
    "np.random.seed(1)  # Consistent values for train/test (for this )\n",
    "save_me = dict(\n",
    "    img_arr = img_arr,\n",
    "    img_to_captions = good_img_to_captions,\n",
    "    train_test = np.random.random( (len(img_arr),) ),\n",
    "    stop_words_seen = stop_words_seen,\n",
    ")\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "with open( os.path.join(cache_dir, 'subset_%s_%s.pkl' % ( \n",
    "            t_start.strftime(\"%Y-%m-%d_%H-%M\"), good_img_to_captions_title,)), \n",
    "          'wb') as f:\n",
    "    pickle.dump(save_me, f)\n",
    "    \n",
    "print(\"Subset saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
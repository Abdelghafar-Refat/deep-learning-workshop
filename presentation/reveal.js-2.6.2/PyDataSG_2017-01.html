<!doctype html>
<html lang="en">

 <head>
  <meta charset="utf-8">

  <title>PyDataSG 2017 - Extracting Names using RNNs</title>

  <meta name="description" content="PyDataSG 2017 - Extracting Names using RNNs">
  <meta name="author" content="Martin Andrews">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <!-- For local-loading of fonts (see README for TTF download instructions) -->
  <!-- Load before theme, so that if connected, 'genuine' fonts are downloaded -->
  <link rel="stylesheet" href="fonts/local.css">

  <link rel="stylesheet" href="css/reveal.min.css">
  <link rel="stylesheet" xhref="css/theme/default.css" href="css/theme/sky.css" id="theme">

  <!-- For syntax highlighting -->
  <link rel="stylesheet" href="lib/css/zenburn.css">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
   if( window.location.search.match( /print-pdf/gi ) ) {
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = 'css/print/pdf.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
   }
  </script>

  <!--[if lt IE 9]>
  <script src="lib/js/html5shiv.js"></script>
  <![endif]-->
 </head>

 <body>
  <div class="reveal">
   <!-- Any section element inside of this container is displayed as a slide -->
   <div class="slides">
    
<style>
table.table-fix {
 margin-left:auto;  margin-right:auto; border-collapse:collapse; cell-padding:5px;
 margin-top:20px;
}
.table-fix td,.table-fix th {
 padding: 6px;
}
.table-fix th {
 border-bottom:1pt solid black;
}
.fix-spacing li {
 margin-bottom:16pt;
}
#all-sessions li span {
   width:100px;
}
</style>

<!--

Reminder : 

Just as a quick reminder in preparation for Monday night's talk : 
If you want to get the most out of the 'middle 30 minutes' of the talk, 
please bring a laptop with VirtualBox already installed on it.  USB keys with
a complete VirtualBox Appliance will be passed round, so that a whole 
sandboxed working environment can be brought up on your own machine instantly 
- which includes the RNN-for-NLP example using that we'll be walking through in detail.


Outline
  (as below)
  Hand out USB keys (only used for middle 1/3

30mins
  Intro to NNs (very quick)
    Describe in terms that make sense w.r.t. Playground
    Experiment with Playground

  Basic problem : words are '1 off'
    Embeddings

  Another problem : sentences have variable length
    Intro to RNNs
    GRU
    LSTM


30mins
  Tagger


30mins
  Other structures
    Language translation
    Attention
    Q&A (Socher?)

  Job Ad - direct with RCL
    Intern
    FTE 
    
  TensorFlow Meetup Ad
    16-Feb 
    +++

Wrap up

!-->

<section>
 <h1>Extracting Names using RNNs</h1>
 <h3>PyDataSG Jan-2017</h3>
 <p>
  <small><a href="http://mdda.net">Martin Andrews</a> @ <a href="http://redcatlabs.com/">redcatlabs.com</a></small>
 </p>
 <p>
  <small>23 January 2017</small>
 </p>
</section>

<section>
 <h2>About Me</h2>
 <ul class="fix-spacing">
  <li>Machine Intelligence / Startups / Finance</li>
  <li style="list-style-type:none">
    <ul>
      <li>Moved from NYC to Singapore in Sep-2013</li>
    </ul>
  </li>
  <li>2014 = 'fun' :</li>
  <li style="list-style-type:none">
    <ul>
      <li>Machine Learning, Deep Learning, NLP</li>
      <li>Robots, drones</li>
    </ul>
  </li>
  <li>Since 2015 = 'serious' :: NLP + deep learning</li>
  <li style="list-style-type:none">
    <ul>
      <li>&amp; Papers...</li>
    </ul>
  </li>
 </ul>
</section>

<section>
  <section>
   <h2>RNNs for NLP</h2>
   <ul class="fix-spacing">
    <li>Natural Language Processing</li>
    <li>Neural Networks</li>
    <li style="list-style-type:none">
      <ul>
        <li>Basics</li>
        <li>Word Embeddings</li>
        <li>Recurrent Neural Networks</li>
      </ul>
    </li>
    <li>Workshop : UPPER-CASE NER</li>
    <li>More exotic examples</li>
   </ul>
  </section>
</section>

<section>
  <section>
   <h2>Natural Language Processing</h2>
   <ul class="fix-spacing">
    <li>Work with text input</li>
    <li>Applications in :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Text Analysis</li>
        <li>Translation</li>
        <li>Knowledge Extraction</li>
      </ul>
    </li>
   </ul>
  </section>
</section>

<section>
  <section>
   <h2>Digression : Basic Neural Networks</h2>
   <ul class="fix-spacing">
    <li>Basic building blocks are not magical</li>
    <li>Simple mathematical units ...</li>
    <li style="list-style-type:none"> ... combine to compute a complex function</li>
   </ul>
  </section>

  <section>
   <h2>Single "Neuron"</h2>
   <img width="602" height="381" src="img/one-neuron_602x381.png" alt="One Neuron" style="border:none;box-shadow:none">
   <p>Change weights to change output function</p>
  </section>

  <section>
   <h2>Multi-Layer</h2>
   <p>Layers of neurons combine to<br/>form more complex functions</p>
   <img width="356" height="324" src="img/multi-layer_356x324.png" alt="Multi-Layer" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Supervised Learning</h2>
   <ul class="fix-spacing">
    <li><strong>while</strong> not done :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Pick a training case (<code>x</code> &rarr; <code>target_y</code>)</li>
        <li>Evaluate <code>output_y</code> from the <code>x</code></li>
        <li>Modify the weights so that <code>output_y</code> is closer to <code>target_y</code> for that <code>x</code></li>
      </ul>
    </li>
   </ul>
  </section>

<!--
  <section>
   <h2>Gradient Descent</h2>
   <p>Follow the gradient of the error <br />vs the connection weights</p>
   <img width="364" height="306" src="img/gradient-descent_364x306.png" alt="Gradient-Descent" style="border:none;box-shadow:none">
  </section>
!-->
  
  <section>
   <h2>Backpropagation</h2>
   <ul class="fix-spacing">
    <li>How much 'blame' to assign to a weight?</li>
    <li>If it is connected to an output : Easy</li>
    <li>Otherwise, calculate :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Blame to assign to each neuron in layer before output</li>
        <li>Treat each of these errors as a source of error signal</li>
        <li>Walk back through network</li>
      </ul>
    </li>
    <li>Same complexity as forward pass</li>
   </ul>
  </section>
</section>

<section>
  <section>
   <h2>What's Going On Inside?</h2>
   <ul>
    <li>Time to look at : </li>
    <li style="list-style-type:none">
     <ul>
      <li>Input features</li>
      <li>What each neuron is learning</li>
      <li>How the training converges</li>
     </ul>
    </li>
   </ul>
  </section>
  
  <section>
   <h2>Workshop : Internals</h2>
   <ul>
    <li style="list-style-type:none">
     <ul>
      <li>Go to the Javascript Example : TensorFlow</li>
     </ul>
    </li>
   </ul>
   <img width="507" height="387" src="img/Tensorflow-PlayGound-local_507x387.png" alt="TensorFlow Playground" style="border:none;box-shadow:none">
   <p><small>(or search online for TensorFlow Playground)</small></p>
  </section>
  
  <section>
   <h2>TensorFlow Playground</h2>
   <img width="778" height="443" src="img/Tensorflow-PlayGound-layout_778x443.png" alt="TensorFlow Layout" style="border:none;box-shadow:none">
  </section>

<!--
  <section>
   <h2>Things to Do</h2>
   <ul>
    <li>Investigate : </li>
    <li style="list-style-type:none">
     <ul>
      <li>Minimal set of features</li>
      <li>Minimal # of layers</li>
      <li>Minimal widths</li>
      <li>Effect of going less-minimal...</li>
     </ul>
    </li>
   </ul>
  </section>
!-->
</section>


<section>
  <section>
   <h2>NNs for Images</h2>
   <ul class="fix-spacing">
    <li>Add 'convolutions' and depth</li>
    <li>Can map images to classes</li>
   </ul>
  </section>
  
  <section>
   <h2>NNs for NLP?</h2>
   <ul class="fix-spacing">
    <li>Problem : Is a word a feature?</li>
    <li>Problem : How long is a sentence?</li>
   </ul>
  </section>
</section>


<section>
  <section>
   <h2>Handling Words</h2>
   <ul class="fix-spacing">
    <li>English ~100k words</li>
    <li>A 'one-hot' input seems wasteful</li>
    <li>Learn about word inter-relationships from corpus?</li>
   </ul>
  </section>
  
  <section>
   <h2>Word Embeddings</h2>
   <ul class="fix-spacing">
    <li>Major advances : word2vec &amp; GloVe</li>
    <li>Basic idea : assign a vector (~300d) to each word</li>
    <li>If words in window 'close', vectors should be closer</li>
    <li>... gradient descent until finished</li>
   </ul>
  </section>

  <section>
   <h2>Word Embedding</h2>
   <ul class="fix-spacing">
    <li>A map from <code>"token"</code> &rarr; <code>Float[100]</code></li>
    <li>Train over corpus on windows of words</li>
    <li>Self-organizes...</li>
   </ul>
   <img width="462" height="174" src="img/embedding_462x174.png" alt="Word Similarity" style="border:none;box-shadow:none">
   <p><small>(eg: <code>word2vec</code> or <code>GloVe</code>)</small></p>
  </section>

  <section>
   <h2>Embedding Visualisation</h2>
   <img width="753" height="264" src="img/Word-Analogies_753x264.png" alt="Word Analogies" style="border:none;box-shadow:none">
   <p>Highlighting Analogies</p>
  </section>

</section>

<!--
<section>
  <section>
   <h2>RNNs for NLP</h2>
   <h4>Sentences are Variable-length</h4>
   <ul class="fix-spacing">
    <li>Apply a network iteratively over input</li>
    <li>Internal state carried forward step-wise</li>
    <li>Everything is still <i>differentiable</i></li>
   </ul>
  </section>

</section>
!-->

<section>
  <section>
   <h2>Networks on Sequences</h2>
   <h4>Variable-length input doesn't "fit"</h4>
   <ul class="fix-spacing">
    <li>Apply a network iteratively over input</li>
    <li>Internal state carried forward step-wise</li>
    <li>Everything is still <i>differentiable</i></li>
   </ul>
  </section>

  <section>
   <h2>Recurrent Neural Networks</h2>
   <ul class="fix-spacing">
    <li>Process each timestep</li>
    <li>... with the same network</li>
    <li>But 'pass along' internal state</li>
   </ul>
  </section>
  
  <section>
   <h2>Basic RNN</h2>
   <img width="677" height="178" src="img/RNN-Chain_677x178.png" alt="RNN Chain" style="border:none;box-shadow:none">
   <p>RNN chain</p>
   <!-- http://colah.github.io/posts/2015-08-Understanding-LSTMs/ !-->
  </section>

  <section>
   <h2>Chaining State</h2>
   <ul class="fix-spacing">
    <li>Each node 'knows' history</li>
    <li>... all weights are 'tied'</li>
    <li>Network depth is time-wise</li>
   </ul>
  </section>
  
  <section>
   <h2>Basic RNN</h2>
   <img width="645" height="243" src="img/RNN-Simple_645x243.png" alt="Simple RNN" style="border:none;box-shadow:none">
   <p>Simplest RNN ~ gradient problem</p>
  </section>

  <section>
   <h2>GRU Units</h2>
   <img width="651" height="251" src="img/RNN-GRU_651x251.png" alt="GRU" style="border:none;box-shadow:none">
   <p>A GRU</p>
   <!-- https://www.opendatascience.com/conferences/recurrent-neural-networks-for-text-analysis-alec-radford/ !-->
  </section>

  <section>
   <h2>LSTM Units</h2>
   <img width="412" height="470" src="img/LSTM_412x470.png" alt="LSTM" style="border:none;box-shadow:none">
   <p>A Long Short-Term Memory (LSTM) Unit</p>
  </section>

  <section>
   <h2>Piled Higher and Deeper</h2>
   <ul class="fix-spacing">
    <li>Can also pile up layers</li>
    <li>... and run forwards and backwards</li>
   </ul>
  </section>
  
</section>

<section>
 <h3>- QUESTIONS -</h3>
</section>

<section>
  <section>
   <h2>NER : Motivation</h2>
   <ul class="fix-spacing">
    <li>Build a quality NLP system for a Singapore startup</li>
    <li>Essential component : Named Entity Recognition (NER)</li>
    <li>Cannot use most existing NLP/NER systems</li>
    <li>Cannot use expensive data</li>
   </ul>
  </section>
  
  <section>
   <h2>NER : Quick Example</h2>
   <ul class="fix-spacing">
    <li>Transform :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Soon after his graduation, Jim Soon became Managing Director of Lam Soon.</li>
      </ul>
    </li>
    <li>Into :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Soon after his graduation, <code>Jim_Soon<small> PER</small></code> became Managing Director of <code>Lam_Soon<small> ORG</small></code>.</li>
      </ul>
    </li>
   </ul>
  </section>

  <section>
   <h2>Learning Named Entity Recognition</h2>
   <ul class="fix-spacing">
    <li>Can we train an RNN to do 'NER'?</li>
    <li>Human annotated Corpora are difficult to distribute :</li>
    <li style="list-style-type:none">
      <ul>
        <li>Use NLTK to annotate Wikipedia</li>
        <li>Train RNN on machine annotations</li>
        <li>Look at performance vs NLTK</li>
      </ul>
    </li>
    <li><b>Twist : Restrict RNN input to single case text</b></li>
   </ul>
  </section>


  <section>
   <h2>9-RNN-Tagger</h2>
   <img width="582" height="311" src="img/RNN-Tagger_582x311.png" alt="RNN-Tagger" style="border:none;box-shadow:none">
   <p>Learning to do ~NER</p>
  </section>

  <section>
   <h2>Network Picture</h2>
   <img width="688" height="243" src="img/RNN-Tagger-Bidirectional-Network_688x243.png" alt="RNN Tagger Network" style="border:none;box-shadow:none">
   <p>Bidirectional RNN</p>
  </section>

</section>

<section>
 <h3>- QUESTIONS -</h3>
</section>

<section>
  <section>
   <h2>Chaining Outputs to Inputs</h2>
   <ul class="fix-spacing">
    <li>Each node outputs vector</li>
    <li>Can softmax-choose 'answer'</li>
    <li>Feed that 'answer' in as next <i>input</i></li>
   </ul>
  </section>
  
  <section>
   <h2>Network Picture</h2>
   <img width="675" height="483" src="img/RNN-output-to-input-chaining_675x483.png" alt="RNN Output to Input Chaining" style="border:none;box-shadow:none">
   <p>Each output becomes the next input</p>
  </section>

</section>


<section>
  <section>
   <h2>Learning Character Sequences</h2>
   <p>... work-in-progress ...</p>
  </section>

  <section>
   <h2>8-Natural-Language</h2>
   <img width="593" height="340" src="img/RNN-Characterwise_593x340.png" alt="RNN Characterwise" style="border:none;box-shadow:none">
   <p>Still a work-in-progress (training takes too long)</p>
  </section>

  <section>
   <h2>Poetry : Epoch 1</h2>
   <pre><code data-trim contenteditable>
JDa&amp;g#sdWI&amp;MKW^gE)I}&amp;lt;UNK>f;6g)^5*|dXdBw6m\2&amp;XcXVy\ph8G&amp;lt;gAM&amp;>e4+mv5}OX8G*Yw9&amp;n3XW{h@&amp;T\Fk%BPMMI
OV&amp;*C_] ._f$v4I~$@Z^&amp;[2
mOVe`4W)"L-KClkO]wu]\$LCNadyo$h;>$jV7X$XK#4,T(y"sa6W0LWf\'_{\#XD]p%ck[;O`!Px\#E>/Or(.YZ|a]2}q|@a9.g3nV,U^qM	$+:nlk0sd;V-Z&amp;;7Y@Z "l-7P^C
"xBF~~{n} n\ Pcbc9f?=y)FIc1h5kvjIi
C&amp;lt;UNK>s	DWJr_$ZQtu"BTYm'|SMj-]Z&amp;lt;Vqj*.lh%IYW|q.GK:eNI"r>833?+RuUsOj_)a{\T}gH.zZR^(daC3mg5P0iFi]bqGo4?T|\>0_H&amp;g889voTh=~)^DDRYND46z1J]x;&amp;lt;U>>%eNIRckL)N8n&amp;lt;UNK>n3i)+Ln8
?)9.#s7X]}$*sxZ"3tf ")
@'HW.;I5)C.*%}&amp;lt;jcNLN+Z__RWoryOb#
/`r
   </code></pre>
  </section>
  
  <section>
   <h2>Poetry : Epoch 100</h2>
   <pre><code data-trim contenteditable>
Som the riscele his nreing the timest stordor hep pIs dach suedests her, so for farmauteds?
By arnouy ig wore
Thou hoasul dove he five grom ays he bare as bleen,
The seend,
And, an neeer,
Whis with the rauk with, for be collenss ore his son froven faredure:
Then andy bround'd the CowE nom shmlls everom thoy men ellone per in the lave ofpen the way ghiind, thour eyes in is ple gull heart sind, I I wild,
Frreasuce anspeve, wrom fant beiver, not the afan
And in thou' histwish a it wheme-tis lating ble the liveculd;
Noorroint he fhallought, othelts.
   </code></pre>
  </section>
  
  <section>
   <h2>Poetry : Epoch 1000</h2>
   <pre><code data-trim contenteditable>
AWhis grook my glass' to his sweet,
Bub my fears liken?
And of live every in seedher;
A Lood stall,
But tare tought than thencer sud earth,
Use'st bee sechion,
For all exprit' are a daud in heaven doth her infook perust the fork the tent.

For maud,
The pittent gover
This and rimp,
Who new
  
Thoir oldes and did hards, cound.
   </code></pre>
  </section>
  
  <section>
   <h2>Plays : Epoch 338</h2>
   <h3>Larger network...</h3>
   <pre><code data-trim contenteditable>
DEDENIUS	Why shoulmeying to to wife,
	And thou say: and wall you teading for
	that struke you down as sweet one.
	With be more bornow, bly unjout on the account:
	I duked you did four conlian unfortuned drausing-
	to sicgia stranss, or not sleepplins his arms
	Gentlemen? as write lord; gave sold.

AENEMUUNS	Met that will knop unhian, where ever have
	of the keep his jangst?icks he I love hide,
	Jach heard which offen, sir!'

	[Exit PATIIUS, MARGARUS arr	[Enter CLOTHUR]
   </code></pre>
  </section>
<!--
!-->
</section>

<section>
  <section>
   <h2>RNN Discrimination</h2>
   <ul class="fix-spacing">
    <li>Can we train an RNN to detect words vs junk?</li>
    <li>Corpus : 100k word dictionary</li>
    <li>Twist : Perhaps we can generate words too...</li>
   </ul>
  </section>

  <section>
   <h2>9-RNN-Fun</h2>
   <img width="581" height="293" src="img/RNN-Fun_581x293.png" alt="RNN-Fun" style="border:none;box-shadow:none">
   <p>RNN Discriminator &amp; more</p>
  </section>

  <section>
   <h2>Discriminator Network</h2>
   <img width="725" height="286" src="img/RNN-discriminator-network_725x286.png" alt="RNN Discriminator Network" style="border:none;box-shadow:none">
  </section>

  <section>
   <h2>Generator Network</h2>
   <img width="567" height="493" src="img/RNN-generator-network_567x493.png" alt="RNN Generator Network" style="border:none;box-shadow:none">
  </section>

</section>

<section>
 <h3>- QUESTIONS -</h3>
</section>

<section>
 <h2>Conclusion</h2>
 <ul class="fix-spacing">
  <li>Deep Learning also applicable to NLP</li>
  <li>Language structure not as 'natural' as images</li>
  <li>Still in its early stages</li>
 </ul>
 <img width="517" height="223" src="img/GitHub-mdda_517x223.png" alt="GitHub - mdda" style="border:none;box-shadow:none">
 <p><small>* Please add a star... *</small></p>
</section>

<section>
 <h1>Feedback</h1>
 <h3>Martin.Andrews @<br> RedCatLabs.com</h3>
 <br>
 <p>My blog : <a href="https://mdda.net/">http://mdda.net/</a></p>
 <p>GitHub : <a href="https://github.com/mdda">mdda</a></p>
</section>

   </div>
  </div>

<div id="redcatlabs-logo" style="background: url(img/redcatlabs_logo1_280x39.png);
                                  position: absolute;
                                  bottom: 50px;
                                  left: 50px;
                                  width: 280px;
                                  height: 39px;">
</div>  

  <script src="lib/js/head.min.js"></script>
  <script src="js/reveal.min.js"></script>

  <script>

   // Full list of configuration options available here:
   // https://github.com/hakimel/reveal.js#configuration
   Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,

    theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
    transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

    // Parallax scrolling
    // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
    // parallaxBackgroundSize: '2100px 900px',

    // Optional libraries used to extend on reveal.js
    dependencies: [
     { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
     { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
     { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
     { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
     { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
    ]
   });

  </script>

 </body>
</html>
